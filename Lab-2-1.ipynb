{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alexwolson/carte-biozone-workshop/blob/main/Lab-2-1.ipynb)\n",
    "\n",
    "# CARTE-BioZone Workshop on Machine Learning\n",
    "#### Tuesday, August 29, 2023\n",
    "#### Lab 1, Day 2: Decision Trees\n",
    "##### Lab author: Alex Olson\n",
    "\n",
    "#### Introduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if we are running on Google Colab, or locally\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not IN_COLAB:  # Colab already has these installed\n",
    "    !pip install -q numpy scikit-learn pandas\n",
    "# Always need to install xgboost and shap\n",
    "!pip install -q xgboost shap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPXh7nee-LHv"
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import scikit-learn libraries for data handling and preprocessing\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Import tree-based classifiers\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Import other boosting classifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sometimes Graphviz is a pain to install. This worksheet will work without it, but you won't be able to visualize the trees\n",
    "try:\n",
    "    import graphviz\n",
    "    from sklearn.tree import export_graphviz\n",
    "\n",
    "    graphviz_installed = True\n",
    "except:\n",
    "    print(\"Graphviz is not installed. You will not be able to visualize the trees\")\n",
    "    graphviz_installed = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7CedHdx-LHw"
   },
   "source": [
    "### Decision Trees\n",
    "\n",
    "Decision trees are popular supervised learning methods used for classification and regression. The tree represents a series of simple decision rules that predict the target when the feature vector is passed through them. Decision trees are easy to understand, can be visualized nicely, require very little data preparation (e.g., we don't need to scale features), and the trained model can be explained easily to others post priori (as opposed to other *black box* methods that are difficult to communicate).\n",
    "\n",
    "###### Example\n",
    "Suppose you wanted to design a simple decision tree for whether (or not) you buy a used car. You might develop something like the following:\n",
    "\n",
    "<img src=\"https://github.com/lyeskhalil/mlbootcamp/blob/master/img/decision-tree.gif?raw=1\" width=\"500\"/>\n",
    "\n",
    "**YOUR TURN:** Let's say you're browsing Kijiji and come across a used car that: has been road tested, has high mileage, and is a recent year/model.\n",
    "* According to your decision tree model, should you buy this car or not? ____________________________\n",
    "* Will you buy any cars that haven't been road tested (if you follow your model)? ___________________________________\n",
    "\n",
    "Obviously this tree may not be ideal, depending on the situation. For example, you could have a road tested car of a recent year with 2,000,000 km's on it and the model is telling you to buy! (But, you probably shouldn't)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Titanic Survivor Dataset**\n",
    "\n",
    "In this lab, we will be exploring the use of decision trees in the context of Kaggle's famous **Titanic dataset**. Each row in the data represents a passenger, detailing various characteristics about them (i.e., the features), and also details whether or not the passenger survived the disaster.\n",
    "\n",
    "Let's load the data and take a look at it.\n",
    "\n",
    "To get the data into a manageable format, we're going to use the [Pandas](https://pandas.pydata.org/) library, a popular library for data manipulation and analysis. While we won't be providing a full Pandas tutorial, we will provide some insight into key functions."
   ],
   "metadata": {
    "id": "litVF00HrKud"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDl1JKwx-LHx"
   },
   "outputs": [],
   "source": [
    "full_data = fetch_openml(\n",
    "    \"titanic\", version=1, as_frame=True, parser=\"auto\"\n",
    ")  # Get all data and metadata\n",
    "data = full_data.frame  # Extract the relevant data\n",
    "data.survived = pd.to_numeric(data[\"survived\"])\n",
    "data.drop(\n",
    "    [\"boat\", \"body\", \"home.dest\"], axis=1, inplace=True\n",
    ")  # Drop irrelevant columns\n",
    "data.head()  # view the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ulk4gvl-LHz"
   },
   "source": [
    "The above cell used the `fetch_openml` function to pull in the Titanic survivor data. The `.head()` allows us to conveniently take a glance at the first 5 rows (along with the header).\n",
    "\n",
    "We can see that, along with the target 'Survived', we have a number of features including the passenger name, sex, age, fare, cabin, etc. We can do a bit of simple *exploratory data analysis* (EDA) to get a better feel for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDz5AhGs-LHz"
   },
   "outputs": [],
   "source": [
    "passengers, features = data.shape\n",
    "survived_count = data[data[\"survived\"] == 1].shape[0]\n",
    "didnt_survive_count = data[data[\"survived\"] == 0].shape[0]\n",
    "female_count = data[data[\"sex\"] == \"female\"].shape[0]\n",
    "male_count = data[data[\"sex\"] == \"male\"].shape[0]\n",
    "missing_values = data.isna().sum()\n",
    "\n",
    "print(f\"Passengers, features: {passengers}, {features}\")\n",
    "print(f\"Survived: {survived_count}, Didn't: {didnt_survive_count}\")\n",
    "print(f\"Female: {female_count}, Male: {male_count}\")\n",
    "print(f\"\\nMissing values by feature:\\n{missing_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfTLCpGf-LH0"
   },
   "source": [
    "As you can see, we can use Pandas to conveniently summarize key aspects of the dataset such as the number of passengers, features, survived/didn't, and their gender. We are also able to identify the number of missing values per feature in the dataset.\n",
    "\n",
    "To accomplish this, we used Pandas flexible indexing capability. The syntax `data[data[col]==val]` allows us to return the subset of rows in `data` where column `col` takes on value `val`. Very powerful!\n",
    "\n",
    "As you may have suspected, the dataset we're using is actually a subset of the total Titanic data. In reality, there were actually 3,547 passengers while the data we're working with only concerns 1309 of them.\n",
    "\n",
    "**YOUR TURN:**\n",
    "Using similar syntax, answer the following questions about the data:\n",
    "* In the dataset, what is the passenger survival rate? ____________________________\n",
    "* How many passengers paid more than $10 for fare? ____________________________\n",
    "* How many passengers had a passenger class (Pclass) of 3? ________________________\n",
    "* With some discussion/exploration and try to determine what features might be the most relevant to passenger survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qH9urfd-LH1"
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "##\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LB5y8KEa-LH2"
   },
   "source": [
    "##### Data Preparation: Categorical -> Numerical Mapping\n",
    "\n",
    "Before we can fit sklearn decision trees to our data, we first need to convert all of the categorical variables (e.g., gender) numerical values - this is called *encoding*. In previous labs, we dealt with datasets that were pre-prepared; now things are getting a little more realistic! Categoricals with unique values (like name and ticket #) can be removed from the dataset entirely as we don't suspect they will contribute to the model.\n",
    "\n",
    "We can do the required preparation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WjofYtW-LH2"
   },
   "outputs": [],
   "source": [
    "# Define the columns to be dropped as they are considered unimportant\n",
    "unimportant_columns = [\"name\", \"ticket\", \"cabin\", \"embarked\"]\n",
    "data = data.drop(unimportant_columns, axis=1)\n",
    "\n",
    "# Create a label encoder for the 'sex' column\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(data[\"sex\"])  # Learn the classes (male/female) from the 'sex' column\n",
    "data[\"sex\"] = label_encoder.transform(\n",
    "    data[\"sex\"]\n",
    ")  # Apply the encoding to the 'sex' column\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-a-uiu0-LH3"
   },
   "source": [
    "In the above cell, we dropped a number of columns we don't suspect will be correlated with the target (*Note: we probably should have been a bit more rigorous about this!*). Then we used the `LabelEncoder()` within sklearn that can fit a numbering scheme to a categorical feature (i.e., 'Sex'). We can see in the new dataset, sex takes on a value of 0 (female) or 1 (male).\n",
    "\n",
    "##### Model Development\n",
    "\n",
    "OK! Let's get to developing some decision tree models to predict passenger survival. We will start with simple decision trees and develop more complex models from there. Our first step, as in previous labs, is to split our data into a training set and a test set (unseen data). We will then use k-folds cross validation on the training set to try and get the best performing model before finally applying it to the test data.\n",
    "\n",
    "Let's import sklearn's decision tree classifer and split the data (using techniques we covered in the first lab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXuxpDkP-LH3"
   },
   "outputs": [],
   "source": [
    "target_data = data[\"survived\"]\n",
    "feature_data = data.iloc[:, data.columns != \"survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_data, target_data, test_size=0.3, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4U5WwH2-LH4"
   },
   "source": [
    "**YOUR TURN:**\n",
    "* How many samples are in the training set? _______________________\n",
    "* How many samples are in the test set? _______________________\n",
    "* What are the survival rates in each of the datasets? ______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANVOauwm-LH4"
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "##\n",
    "##\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZp4c8Hg-LH5"
   },
   "source": [
    "##### Dealing with Missing Data: Imputation\n",
    "\n",
    "Before we can fit our decision tree to our training data, we can conduct *imputation* to replace missing values with the mean/median/mode value in the column. For this exercise we will conduct mode imputation (i.e., the most common value in the column).\n",
    "\n",
    "**YOUR TURN:** Assuming we have a feature vector with three rows where 'nan' is a missing value:\n",
    "X = [[1, 2, 3],\n",
    "     [1, 2, nan],\n",
    "     [2, 3, 2]]\n",
    "* Which sample has a missing value? (the 1st, 2nd or 3rd?) ______________________________\n",
    "* If we *impute* (i.e., replace the missing value with another value) using the mean (average), what value will go in place of the nan value? __________________________________\n",
    "\n",
    "It's important that you don't impute your data using statistics including the the test data! This is an example of *information leak* where your test data is leaking into your training data.\n",
    "\n",
    "As such, we will fit our missing data imputer to our training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQFGk9hk-LH5"
   },
   "outputs": [],
   "source": [
    "# Create an imputer object to handle missing values, using the 'most_frequent' strategy\n",
    "missing_value_imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "\n",
    "# Fit the imputer using the training data\n",
    "missing_value_imputer.fit(X_train)\n",
    "\n",
    "# Transform the training data, replacing missing values with the most frequent value in each column\n",
    "X_train = missing_value_imputer.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqj-hPeg-LH6"
   },
   "source": [
    "So we've got our data prepared, let's fit a decision tree to our training data.\n",
    "\n",
    "Remember, the pipeline for model development in sklearn is **initialize->fit->predict**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqxAAXVU-LH6"
   },
   "outputs": [],
   "source": [
    "# Create a Decision Tree Classifier\n",
    "decision_tree_classifier = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the accuracy on the training set\n",
    "training_accuracy = accuracy_score(y_train, decision_tree_classifier.predict(X_train))\n",
    "print(f\"Training Accuracy: {training_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1yMNmyr-LH6"
   },
   "source": [
    "In the above cell, we defined a Decision Tree classifier and fit it to our training set. When we then used it to predict training set values, the resulting accuracy was ~97%.\n",
    "\n",
    "**YOUR TURN:**\n",
    "* Since we are both training and predicting on our training set, why didn't the decision tree achieve 100% accuracy? (like our nearest neighbor approach with k=1)?\n",
    "* What is the performance of this model on the test set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4vftzMR-LH7"
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "##\n",
    "##\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4KZ5J-t-LH7"
   },
   "source": [
    "##### Feature Importances\n",
    "\n",
    "One thing we can do is take a look at the relative feature importances of the trained decision tree classifier. This will give us an idea of what the model thinks is more/less important for properly predicting the target.\n",
    "\n",
    "Let's look at the feature importances for a model on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-1ZcqEN-LH7"
   },
   "outputs": [],
   "source": [
    "feature_importances = decision_tree_classifier.feature_importances_\n",
    "feature_columns = feature_data.columns\n",
    "\n",
    "for feature, importance in sorted(\n",
    "    zip(feature_columns, feature_importances), key=lambda x: x[1], reverse=True\n",
    "):\n",
    "    print(f\"{feature}:\\t{importance * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HL_BERf-LH8"
   },
   "source": [
    "As we can see, the tree is placing a higher importance on Sex, Age, and Fare paid. These are interesting observations that we could dig a little deeper into if we wanted to.\n",
    "\n",
    "#### Visualizing the Tree\n",
    "\n",
    "One useful thing we can do is actually visualize our decision tree model! We can use the [graphViz](https://www.graphviz.org/) library to accomplish this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQ2xJfJm-LH8"
   },
   "outputs": [],
   "source": [
    "if graphviz_installed:\n",
    "    export_graphviz(\n",
    "        decision_tree_classifier, out_file=\"mytree.dot\", feature_names=feature_columns\n",
    "    )\n",
    "    with open(\"mytree.dot\") as f:\n",
    "        dot_graph = f.read()\n",
    "else:\n",
    "    print(\n",
    "        \"Graphviz is not installed. You will not be able to visualize the trees using Graphviz.\"\n",
    "    )\n",
    "    print(\"Generating a text representation of the tree instead:\")\n",
    "    tree.plot_tree(decision_tree_classifier, feature_names=list(feature_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graphviz.Source(dot_graph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EgolEWB-LH8"
   },
   "source": [
    "**YOUR TURN:** Explore the decision tree and answer the following:\n",
    "* What feature does the root node split on?\n",
    "* What is the depth of the decision tree (i.e., the length of the longest path from root to leaf)?\n",
    "* Do you think this decision tree is prone to overfitting? Why/why not?\n",
    "\n",
    "To reduce the degree to which this tree is overfit to the training data, we can force the tree to be of some *maximum depth*. This ensures the tree won't be able to just keep generating new layers to properly classify every sample in the training stage (and, thus, presumably generalize better to the test set).\n",
    "\n",
    "Let's try limiting the max depth to 2 and visualizing the resulting tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uDkSy0a-LH9"
   },
   "outputs": [],
   "source": [
    "# Define and fit the Decision Tree Classifier with max depth of 2\n",
    "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=2)\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Define feature names\n",
    "feature_columns = data.columns.drop(\"survived\")\n",
    "\n",
    "# Visualization code with Graphviz\n",
    "if graphviz_installed:\n",
    "    export_graphviz(\n",
    "        decision_tree_classifier, out_file=\"mytree.dot\", feature_names=feature_columns\n",
    "    )\n",
    "    with open(\"mytree.dot\") as f:\n",
    "        dot_graph = f.read()\n",
    "else:\n",
    "    print(\n",
    "        \"Graphviz is not installed. You will not be able to visualize the trees using Graphviz.\"\n",
    "    )\n",
    "    print(\"Displaying a text representation of the tree instead:\")\n",
    "    tree.plot_tree(decision_tree_classifier, feature_names=feature_columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graphviz.Source(dot_graph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUJdXnp--LH9"
   },
   "source": [
    "Much simpler! As we can see, our model finds Age, Sex, and Pclass to be the most important features. We would expect this model to have much poorer performance when predicting on the training set (as opposed to our 97% we got above), but perhaps better performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are many hyper-parameters that can be tuned to change how the model performs. Some common parameters that are modified include:\n",
    "1. Max Tree Depth: How \"tall\" do you want your tree to be\n",
    "2. Minimum Samples Per Leaf: This parameter defines the minimum number of training datapoints that fall into a given leaf node in order for that node to be created\n",
    "3. Minimum Samples to Split: This parameter controls the minimum number of samples required to create a decision split\n",
    "\n",
    "To decide the values of each of the parameters, we can use Grid Search combined with cross validation. In Grid Search, we first decide what potential values we want each hyperparameter will take. Then we find every possible combination of parameters and run cross validation on each combination to estimate the performance of that hyperparameter combination.\n",
    "\n",
    "Luckily, `sklearn` has a nice implementation of Grid Search that runs this algorithm for us. Lets see a demo below:"
   ],
   "metadata": {
    "id": "T2gqE8y3_yXP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define a Decision Tree Classifier without passing in parameters\n",
    "decision_tree_model = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Decide the possible hyperparameter combinations for Grid Search\n",
    "hyperparameter_grid = {\n",
    "    \"max_depth\": [2, 3, 4, 5],\n",
    "    \"min_samples_split\": [2, 5, 8, 11],\n",
    "    \"min_samples_leaf\": [2, 5, 8, 11],\n",
    "}\n",
    "\n",
    "# Define the evaluation metric for Grid Search\n",
    "evaluation_metric = make_scorer(accuracy_score, greater_is_better=True)\n",
    "\n",
    "# Set up Grid Search algorithm with a 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=decision_tree_model,\n",
    "    param_grid=hyperparameter_grid,\n",
    "    scoring=evaluation_metric,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "# Run the Grid Search (Note: This may take a while)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {grid_search.best_score_ * 100:.2f}%\")\n",
    "\n",
    "# Retrieve the best model from the Grid Search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test data and compute the accuracy\n",
    "test_accuracy = accuracy_score(\n",
    "    y_test, best_model.predict(missing_value_imputer.transform(X_test))\n",
    ")\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")"
   ],
   "metadata": {
    "id": "zmpcYAMI_xyX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the cell above, we tested our two values per hyperparameter and ran grid search to find the best combination from the space we defined. As you may have noticed, the number of combinations tested by Grid Search exponentially increases as you test more values and tune more hyperparameters. This means that performing a grid search is often a task that takes a long period of time and is often note used for more complex models like neural networks."
   ],
   "metadata": {
    "id": "Qrr1hd59EiVK"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yotoft9s-LH9"
   },
   "source": [
    "### Random Forests, Gradient Boosting, Extreme Gradient Boosting\n",
    "\n",
    "Let's (briefly) investigate some more advanced tree models that you have learned about and see if we can improve our performance. We will be using the following models in addition to our decision tree classifier:\n",
    "\n",
    "* Scikitlearn Random Forest classifier\n",
    "* Scikitlearn Gradient boosting classifier\n",
    "* XGBoost classifier\n",
    "\n",
    "Note that XGBoost is similar in theory to Scikitlearn's Gradient boosting classifier. However, XGBoost's implementation is highly efficient than that of Scikitlearn's. Forests are *ensemble* techniques that combine multiple decision trees. As you learned in lecture, and as visualized below, random forest methods usually combine multiple trees through some sort of voting scheme.\n",
    "\n",
    "<img src=\"https://github.com/lyeskhalil/mlbootcamp/blob/master/img/random-forest.png?raw=1\" width=\"400\"/>\n",
    "\n",
    "In the above example, two trees vote (predict) Class B and another predicts Class A, so the overall ensemble vote goes to the majority (Class B). Boosting, on the other hand, uses multiple trees in in a stage-wise fashion. Popular machine learning software XGBoost has a great explanation for [how this works](https://xgboost.readthedocs.io/en/latest/tutorials/model.html).\n",
    "\n",
    "Let's build some ensemble classifiers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_8SgflL-LH-"
   },
   "outputs": [],
   "source": [
    "decision_tree_classifier = tree.DecisionTreeClassifier()\n",
    "random_forest_classifier = RandomForestClassifier()\n",
    "gradient_boosting_classifier = GradientBoostingClassifier()\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "decision_tree_scores = cross_val_score(decision_tree_classifier, X_train, y_train, cv=5)\n",
    "random_forest_scores = cross_val_score(random_forest_classifier, X_train, y_train, cv=5)\n",
    "gradient_boosting_scores = cross_val_score(\n",
    "    gradient_boosting_classifier, X_train, y_train, cv=5\n",
    ")\n",
    "xgb_scores = cross_val_score(xgb_classifier, X_train, y_train, cv=5)\n",
    "\n",
    "print(\n",
    "    f\"Decision tree accuracy: {decision_tree_scores.mean():.2f} (+/- {decision_tree_scores.std() * 2:.2f})\"\n",
    ")\n",
    "print(\n",
    "    f\"Random forest accuracy: {random_forest_scores.mean():.2f} (+/- {random_forest_scores.std() * 2:.2f})\"\n",
    ")\n",
    "print(\n",
    "    f\"Gradient boosting accuracy: {gradient_boosting_scores.mean():.2f} (+/- {gradient_boosting_scores.std() * 2:.2f})\"\n",
    ")\n",
    "print(f\"XGBoost accuracy: {xgb_scores.mean():.2f} (+/- {xgb_scores.std() * 2:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX8UnvyN-LH-"
   },
   "source": [
    "We can see that each of the more sophisticated tree/forest methods improves upon the initial decision tree accuracy in terms of cross-validated accuracy.\n",
    "\n",
    "Let's see how the extreme gradient boosted method performs on the hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItWp3hBx-LH_"
   },
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "imputer.fit(X_test)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_classifier.predict(X_test_imputed))\n",
    "\n",
    "print(f\"Test set accuracy: {xgb_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqpxFuwy-LH_"
   },
   "source": [
    "First, we imputed the missing values in the test set (as we had done for the training set) and then we applied our gradient boosting-based classifier (as trained on the training data). We yielded an 80-81% accuracy; not bad!\n",
    "\n",
    "**YOUR TURN:**\n",
    "* What features did the gradient boosting algorithm find the most important? __________________\n",
    "* What is the test set accuracy if, instead, you used the Scikitlearn's gradient boosting algorithm? __________________\n",
    "\n",
    "* If you designed a naive classifier that simply guessed 'did not survive' (i.e., Survived = 0) for every row in the test set, how would it perform? ________________________\n",
    "* Is this better or worse than our gradient boosted tree? ____________________________\n",
    "\n",
    "## Bioscience Applications\n",
    "\n",
    "Decision trees are a popular method in bioscience applications. For example, in the paper [A decision tree-based approach to predicting protein secondary structure content](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC168952/) the authors use decision trees to predict the secondary structure of proteins. In the paper [Decision tree-based method for selecting the best machine learning model for classifying human physical activity](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6320913/) the authors use decision trees to classify human physical activity.\n",
    "\n",
    "Let's take a look at a simple example, using the Pima Indians Diabetes Database. This dataset is a small dataset that contains information about Pima Indians and whether or not they have diabetes. The dataset is available [here](https://www.openml.org/d/37)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes_data = fetch_openml(\"diabetes\", version=1, as_frame=True, parser=\"auto\")\n",
    "diabetes_data.frame.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diabetes_features = diabetes_data.frame.iloc[:, diabetes_data.frame.columns != \"class\"]\n",
    "diabetes_target = diabetes_data.frame[\"class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    diabetes_features, diabetes_target, test_size=0.3, random_state=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a Decision Tree Classifier\n",
    "decision_tree_classifier = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the accuracy on the training set\n",
    "training_accuracy = accuracy_score(y_train, decision_tree_classifier.predict(X_train))\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, decision_tree_classifier.predict(X_test))\n",
    "\n",
    "print(f\"Training Accuracy: {training_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "feature_importances = decision_tree_classifier.feature_importances_\n",
    "feature_columns = diabetes_features.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for feature, importance in sorted(\n",
    "    zip(feature_columns, feature_importances), key=lambda x: x[1], reverse=True\n",
    "):\n",
    "    print(f\"{feature}:\\t{importance * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bonus: Explainability using SHAP\n",
    "\n",
    "Particularly when we are working with sensitive data, it is important to be able to explain the decisions that our models are making. One way to do this is to use the SHAP (SHapley Additive exPlanations) library. SHAP is a game theoretic approach to explain the output of any machine learning model. SHAP values are used to explain the output of machine learning models by quantifying the contribution of each feature to the prediction. SHAP values have their roots in cooperative game theory where the goal is to fairly distribute the \"payout\" among the players. In the context of machine learning, the \"payout\" is the prediction of the model and the \"players\" are the features. SHAP values are calculated using Shapley values, which is a solution concept from cooperative game theory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import shap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load javascript\n",
    "shap.initjs()\n",
    "\n",
    "# Create a SHAP explainer object\n",
    "explainer = shap.TreeExplainer(decision_tree_classifier)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Visualize the first prediction's explanation\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][0, :], X_train.iloc[0, :])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So what are we looking at here? The force plot shows us the features that are most important for the prediction of the first sample. The red/blue color represents whether the feature is pushing the prediction higher (red) or lower (blue). The value of the feature is shown on the x-axis. The higher the value of the feature, the more it pushes the prediction to the right. The base value is the average prediction of the model. The output value is the prediction of the model for the first sample.\n",
    "\n",
    "We can also look at the summary plot to see the global importance of each feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Show summary plot\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values[1], X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, individual points are plotted based on whether they increase or decrease the value of the final prediction. The colour of each point tells us the value of the feature. For example, the red points have a high value of the feature and the blue points have a low value of the feature. The x-axis shows the impact of the feature on the model output. Features are sorted by the sum of the SHAP value magnitudes across all samples. The y-axis shows the feature name. The features are ordered from the most important to the least important. The colour of the feature represents the value of the feature across all samples."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
