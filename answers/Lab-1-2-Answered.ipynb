{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyMcD6m6l8Ut8vEnqam8Fx4F"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "f6d84beb6f8e477a9c0d45817accc8b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3996aef1fc0f4b7ea9a5f6dbaffd4fba",
       "IPY_MODEL_330269805d30447895208d5c4f79e728",
       "IPY_MODEL_adee0055ed694b0a9f643a489d3fb08a"
      ],
      "layout": "IPY_MODEL_76b654fd1e0a4da8b4a3bb949c286086"
     }
    },
    "3996aef1fc0f4b7ea9a5f6dbaffd4fba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e05c7217178646a1b362f13e93d7fc00",
      "placeholder": "​",
      "style": "IPY_MODEL_6f35d1788d3b498ca7dccc8072a36daf",
      "value": "Best trial: 95. Best value: 0.817528: 100%"
     }
    },
    "330269805d30447895208d5c4f79e728": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d85108019624c6bb12a020175c24afe",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0cd81b6de72048c8961aa7778b653a0b",
      "value": 100
     }
    },
    "adee0055ed694b0a9f643a489d3fb08a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a08383cb3b24b129429c401fa4e8df4",
      "placeholder": "​",
      "style": "IPY_MODEL_1b58e8e784a045e08d6605205d63150a",
      "value": " 100/100 [02:04&lt;00:00,  1.24s/it]"
     }
    },
    "76b654fd1e0a4da8b4a3bb949c286086": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e05c7217178646a1b362f13e93d7fc00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f35d1788d3b498ca7dccc8072a36daf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d85108019624c6bb12a020175c24afe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cd81b6de72048c8961aa7778b653a0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9a08383cb3b24b129429c401fa4e8df4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b58e8e784a045e08d6605205d63150a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0aef6ccaf6d43e1b5c400b2307a265e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f21470133c574f5c9d0707c979038cbf",
       "IPY_MODEL_ecf72f14216949e3b93f5f0f78f9baba",
       "IPY_MODEL_6e6a13c6cb6640d2b874207cb29d487e"
      ],
      "layout": "IPY_MODEL_7ea0dc58b97e422283f5822274fa68df"
     }
    },
    "f21470133c574f5c9d0707c979038cbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41c5428891fb4b9e8e00545c027a4794",
      "placeholder": "​",
      "style": "IPY_MODEL_171232bb06a841698fd3af2bef742cb7",
      "value": "Best trial: 86. Best value: 0.79509: 100%"
     }
    },
    "ecf72f14216949e3b93f5f0f78f9baba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf6ad7ae768647b6b317ca2266c9f784",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02f8ea4fe50c495cb38378ca1e16dc6b",
      "value": 100
     }
    },
    "6e6a13c6cb6640d2b874207cb29d487e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c2094a8784c452dbf4bed4c449e1471",
      "placeholder": "​",
      "style": "IPY_MODEL_6a85def097714d12943770ae703d7000",
      "value": " 100/100 [21:26&lt;00:00, 15.40s/it]"
     }
    },
    "7ea0dc58b97e422283f5822274fa68df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41c5428891fb4b9e8e00545c027a4794": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "171232bb06a841698fd3af2bef742cb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf6ad7ae768647b6b317ca2266c9f784": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02f8ea4fe50c495cb38378ca1e16dc6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7c2094a8784c452dbf4bed4c449e1471": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a85def097714d12943770ae703d7000": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alexwolson/carte-biozone-workshop/blob/main/Lab-1-2.ipynb)\n",
    "\n",
    "# CARTE-BioZone Workshop on Machine Learning\n",
    "#### Tuesday, August 29, 2023\n",
    "#### Lab 2, Day 1: Hyperparameter Tuning\n",
    "##### Lab author: Nakul Upadhya (referencing work by Kyle E. C. Booth and Jake Mosseri), edited by Alex Olson"
   ],
   "metadata": {
    "id": "ACsD78d8vjSa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Machine Learning operates by solving an optimization problem to determine the parameters of a function that best fits the data. However, some parameters - known as hyperparameters - can't be learned through this process, as they set the model structure and guide the optimization procedure. Tuning these hyperparameters is a crucial part of model development and can greatly impact model performance.\n",
    "\n",
    "Hyperparameter tuning refers to the task of discovering the optimal hyperparameters for a given model and dataset. This process is a key stage in the machine learning workflow. Nevertheless, it poses a challenging task due to its complex nature - there is no universal methodology that applies to all scenarios. The selection of the best hyperparameters relies heavily on the dataset at hand, the chosen model architecture, and the specific learning task. Therefore, identifying the ideal set of hyperparameters is not about finding a one-size-fits-all solution, but rather about employing a mix of intuition, systematic testing, and optimization techniques.\n",
    "\n",
    "In this lab, we will delve into the fundamentals of hyperparameter tuning, exploring methods such as Grid Search, Cross Validation, and Bayesian Optimization. Let's dive in!"
   ],
   "metadata": {
    "id": "HIPYMpobxpaD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Check if we are running on Google Colab, or locally\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:38:24.776296Z",
     "start_time": "2023-08-28T14:38:24.773130Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    # Colab already has these installed\n",
    "    !pip install -q torch torchvision torchaudio numpy pandas matplotlib scikit-learn\n",
    "!pip install -q optuna"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:38:30.205893Z",
     "start_time": "2023-08-28T14:38:24.779288Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# Import libraries for data handling and manipulation\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_validate,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "import optuna\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHB2yx2Gxpop",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689198423116,
     "user_tz": 240,
     "elapsed": 65609,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "36494fc7-062f-494e-b062-2c7c91e865ea",
    "ExecuteTime": {
     "end_time": "2023-08-28T14:38:35.936613Z",
     "start_time": "2023-08-28T14:38:30.211697Z"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this lab, we'll be using the Titanic dataset. To prepare our dataset for the subsequent learning tasks, we'll have to perform the following steps:\n",
    "\n",
    "1. Discard irrelevant columns: Some columns may not contribute to the model's predictive performance and can be removed.\n",
    "2. Adjust data types of certain columns: Some columns may have incorrect data types that need to be fixed for proper analysis.\n",
    "3. Split the dataset into Training and Test sets: This ensures we have a separate dataset (Test set) to evaluate our model's performance.\n",
    "4. Handle missing values: We need to impute or fill in missing values to avoid complications during the learning process.\n",
    "5. Scale the data: It's necessary to standardize our data to ensure all features have equal importance in model training.\n",
    "\n",
    "We'll be carrying out all these steps in the following cells:"
   ],
   "metadata": {
    "id": "28XanXRqznHx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Fetch data\n",
    "data = fetch_openml(\"titanic\", version=1, as_frame=True, parser=\"auto\").frame\n",
    "\n",
    "# Select features\n",
    "unimportant_cols = [\"name\", \"ticket\", \"cabin\", \"embarked\", \"boat\", \"body\", \"home.dest\"]\n",
    "data = data.drop(unimportant_cols, axis=1)\n",
    "\n",
    "# Encode categorical features and convert relevant columns to numeric data type\n",
    "label_encoder = LabelEncoder()  # Encoder for categorical features\n",
    "data[\"sex\"] = label_encoder.fit_transform(data[\"sex\"])\n",
    "data[\"survived\"] = data[\"survived\"].astype(\"int\")\n",
    "\n",
    "# Split data into features and target\n",
    "target_data = data[\"survived\"]\n",
    "feature_data = data.drop(\"survived\", axis=1)\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_data, target_data, test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "# Handle missing values with imputation\n",
    "imputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy=\"most_frequent\"\n",
    ")  # Imputer for handling missing values\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Print information about the final dataset\n",
    "print(\n",
    "    f\"There are {X_train.shape[0]} training data points and {X_test.shape[0]} testing points\"\n",
    ")\n",
    "print(f\"There are {X_train.shape[1]} features in the dataset\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUNddJ_Ez2gU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689198424388,
     "user_tz": 240,
     "elapsed": 1275,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "09e0c562-fe79-47c1-bc41-d88caac6df82",
    "ExecuteTime": {
     "end_time": "2023-08-28T14:38:35.979447Z",
     "start_time": "2023-08-28T14:38:35.943470Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 981 training data points and 328 testing points\n",
      "There are 6 features in the dataset\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grid Search\n",
    "\n",
    "With our data ready, we can commence our exploration of hyperparameter tuning. Our initial approach will be grid search, a method that involves constructing a grid of potential hyperparameters and systematically examining the model's performance for each combination. To attain a reliable measure of model performance, grid search is often combined with K-Fold cross-validation. The Grid Search CV process involves:\n",
    "\n",
    "1. Hyperparameter grid definition: Identify the hyperparameters to be tuned and designate possible values for each one. This forms a grid, where each point represents a unique set of hyperparameters.\n",
    "2. Cross-validation across folds: For each unique set of hyperparameters, execute a K-Fold Cross-validation on your model and calculate the average error.\n",
    "3. Hyperparameters selection: Opt for the hyperparameters that result in the best performance (i.e., the lowest error).\n",
    "\n",
    "Let's delve into the impact of hyperparameter tuning using a simple Random Forest Classifier in the following section."
   ],
   "metadata": {
    "id": "N5VIfGvg5CJr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Setting up a Random Forest Classifier...\")\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "print(\"Defining hyperparameters for Grid Search...\")\n",
    "hyperparameter_search = {\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],  # Max Depth of each individual tree\n",
    "    \"n_estimators\": [50, 100, 150, 200],  # Number of trees generated\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8],  # Minimum number of samples found in a leaf\n",
    "    \"min_samples_split\": [2, 4, 8, 16, 32],  # Minimum samples required for a split\n",
    "}\n",
    "\n",
    "print(\"Setting up Grid Search with 5-fold Cross Validation...\")\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=hyperparameter_search,\n",
    "    scoring=make_scorer(accuracy_score, greater_is_better=True),\n",
    "    verbose=1,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "print(\"Running Grid Search (This may take a while)...\")\n",
    "start_time = time()\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "\n",
    "print(f\"Grid Search completed in {end_time - start_time:.0f} seconds\")\n",
    "\n",
    "print(f\"Best Parameters: {grid_search_cv.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {grid_search_cv.best_score_ * 100:.2f}%\")\n",
    "\n",
    "print(\"Evaluating model on test data...\")\n",
    "clf = grid_search_cv.best_estimator_\n",
    "test_predictions = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}%\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-t1k64t-O2U",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689198943839,
     "user_tz": 240,
     "elapsed": 519453,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "419c2834-552c-4489-b74b-807b112d8719",
    "ExecuteTime": {
     "end_time": "2023-08-28T14:39:40.978234Z",
     "start_time": "2023-08-28T14:38:37.379097Z"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up a Random Forest Classifier...\n",
      "Defining hyperparameters for Grid Search...\n",
      "Setting up Grid Search with 5-fold Cross Validation...\n",
      "Running Grid Search (This may take a while)...\n",
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "Grid Search completed in 64 seconds\n",
      "Best Parameters: {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Best CV Accuracy: 81.75%\n",
      "Evaluating model on test data...\n",
      "Testing Accuracy: 81.40%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Advanced Parameter Searching\n",
    "\n",
    "While Grid Search proves effective in many scenarios, its major limitation is its computational demand. The number of models to be trained escalates exponentially with each additional hyperparameter. In our previous example, we had to train a model over five thousand times due to the 1024 combinations ($4^5$) and 5-fold cross-validation. This approach might be feasible for simpler models like Random Forests or Linear/Logistic regression, but it becomes prohibitively time-consuming for deep learning models or when dealing with a large search space.\n",
    "\n",
    "## Introducing Bayesian Optimization\n",
    "\n",
    "An alternative hyperparameter tuning technique, Bayesian Optimization, can help mitigate these computational concerns. It's a sequential, model-based optimization method used to find the optimal hyperparameters for a given machine learning model. This technique combines Bayesian inference and optimization to identify promising regions for evaluation, utilizing a surrogate model to approximate the performance of our primary model concerning its hyperparameters.\n",
    "\n",
    "One of the key advantages of Bayesian optimization is its efficient exploration of the hyperparameter space, which provides a significant edge over exhaustive search methods like grid search. It intelligently selects new configurations based on predictions from the surrogate model, thus converging to the optimal hyperparameters more rapidly and with fewer evaluations.\n",
    "\n",
    "Next, let's apply Bayesian Optimization for parameter search in our Random Forest model. We'll leverage Optuna, a hyperparameter optimization library that encapsulates this approach."
   ],
   "metadata": {
    "id": "iznvVdvCA7vj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def print_callback(study, trial):\n",
    "    # Print the trial number, the best value and parameters after each trial\n",
    "    print(f\"\\nTrial {trial.number} finished.\")\n",
    "    print(f\"Best value after trial {trial.number}: {study.best_value:.3f}\")\n",
    "    print(f\"Best params after trial {trial.number}: {study.best_params}\")\n",
    "\n",
    "\n",
    "# Define a function that specifies the model, the search space and trains the model\n",
    "# Optuna will try to optimize the hyperparameters to maximize the output of this function\n",
    "def optuna_rf_function(trial):\n",
    "    hyperparameters = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 8),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 32),\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**hyperparameters)\n",
    "\n",
    "    # Evaluate the model using cross-validation and calculate the mean test score\n",
    "    cv_result = cross_validate(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    return cv_result[\"test_score\"].mean()\n",
    "\n",
    "\n",
    "# Create an Optuna study object\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Optimize the study using the sampler\n",
    "study.optimize(\n",
    "    optuna_rf_function,\n",
    "    n_trials=100,\n",
    "    callbacks=[print_callback],\n",
    "    show_progress_bar=True,\n",
    "    gc_after_trial=True,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f6d84beb6f8e477a9c0d45817accc8b0",
      "3996aef1fc0f4b7ea9a5f6dbaffd4fba",
      "330269805d30447895208d5c4f79e728",
      "adee0055ed694b0a9f643a489d3fb08a",
      "76b654fd1e0a4da8b4a3bb949c286086",
      "e05c7217178646a1b362f13e93d7fc00",
      "6f35d1788d3b498ca7dccc8072a36daf",
      "2d85108019624c6bb12a020175c24afe",
      "0cd81b6de72048c8961aa7778b653a0b",
      "9a08383cb3b24b129429c401fa4e8df4",
      "1b58e8e784a045e08d6605205d63150a"
     ]
    },
    "id": "nEDytL6uA4oU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689199069057,
     "user_tz": 240,
     "elapsed": 125228,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "8625709b-04be-468e-f957-c84f3972c85d",
    "ExecuteTime": {
     "end_time": "2023-08-28T14:41:19.438638Z",
     "start_time": "2023-08-28T14:39:40.984092Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 10:39:40,981] A new study created in memory with name: no-name-6ddf8f5f-3953-47cd-acef-3b6b78e3b369\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d721ee67a69844d8b1d29ccf04fd0c00"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 10:39:42,319] Trial 0 finished with value: 0.7991919610483788 and parameters: {'max_depth': 3, 'n_estimators': 177, 'min_samples_leaf': 5, 'min_samples_split': 9}. Best is trial 0 with value: 0.7991919610483788.\n",
      "\n",
      "Trial 0 finished.\n",
      "Best value after trial 0: 0.799\n",
      "Best params after trial 0: {'max_depth': 3, 'n_estimators': 177, 'min_samples_leaf': 5, 'min_samples_split': 9}\n",
      "[I 2023-08-28 10:39:43,656] Trial 1 finished with value: 0.8042525639697503 and parameters: {'max_depth': 5, 'n_estimators': 183, 'min_samples_leaf': 5, 'min_samples_split': 22}. Best is trial 1 with value: 0.8042525639697503.\n",
      "\n",
      "Trial 1 finished.\n",
      "Best value after trial 1: 0.804\n",
      "Best params after trial 1: {'max_depth': 5, 'n_estimators': 183, 'min_samples_leaf': 5, 'min_samples_split': 22}\n",
      "[I 2023-08-28 10:39:44,329] Trial 2 finished with value: 0.8124054698021341 and parameters: {'max_depth': 7, 'n_estimators': 86, 'min_samples_leaf': 3, 'min_samples_split': 22}. Best is trial 2 with value: 0.8124054698021341.\n",
      "\n",
      "Trial 2 finished.\n",
      "Best value after trial 2: 0.812\n",
      "Best params after trial 2: {'max_depth': 7, 'n_estimators': 86, 'min_samples_leaf': 3, 'min_samples_split': 22}\n",
      "[I 2023-08-28 10:39:45,328] Trial 3 finished with value: 0.8093649642598157 and parameters: {'max_depth': 7, 'n_estimators': 136, 'min_samples_leaf': 3, 'min_samples_split': 2}. Best is trial 2 with value: 0.8124054698021341.\n",
      "\n",
      "Trial 3 finished.\n",
      "Best value after trial 3: 0.812\n",
      "Best params after trial 3: {'max_depth': 7, 'n_estimators': 86, 'min_samples_leaf': 3, 'min_samples_split': 22}\n",
      "[I 2023-08-28 10:39:46,492] Trial 4 finished with value: 0.8022272868538278 and parameters: {'max_depth': 7, 'n_estimators': 177, 'min_samples_leaf': 5, 'min_samples_split': 6}. Best is trial 2 with value: 0.8124054698021341.\n",
      "\n",
      "Trial 4 finished.\n",
      "Best value after trial 4: 0.812\n",
      "Best params after trial 4: {'max_depth': 7, 'n_estimators': 86, 'min_samples_leaf': 3, 'min_samples_split': 22}\n",
      "[I 2023-08-28 10:39:47,253] Trial 5 finished with value: 0.808339376359681 and parameters: {'max_depth': 7, 'n_estimators': 110, 'min_samples_leaf': 4, 'min_samples_split': 10}. Best is trial 2 with value: 0.8124054698021341.\n",
      "\n",
      "Trial 5 finished.\n",
      "Best value after trial 5: 0.812\n",
      "Best params after trial 5: {'max_depth': 7, 'n_estimators': 86, 'min_samples_leaf': 3, 'min_samples_split': 22}\n",
      "[I 2023-08-28 10:39:47,961] Trial 6 finished with value: 0.8073189681964156 and parameters: {'max_depth': 7, 'n_estimators': 103, 'min_samples_leaf': 8, 'min_samples_split': 6}. Best is trial 2 with value: 0.8124054698021341.\n",
      "\n",
      "Trial 6 finished.\n",
      "Best value after trial 6: 0.812\n",
      "Best params after trial 6: {'max_depth': 7, 'n_estimators': 86, 'min_samples_leaf': 3, 'min_samples_split': 22}\n",
      "[I 2023-08-28 10:39:48,689] Trial 7 finished with value: 0.8093546047860768 and parameters: {'max_depth': 6, 'n_estimators': 109, 'min_samples_leaf': 7, 'min_samples_split': 27}. Best is trial 2 with value: 0.8124054698021341.\n",
      "\n",
      "Trial 7 finished.\n",
      "Best value after trial 7: 0.812\n",
      "Best params after trial 7: {'max_depth': 7, 'n_estimators': 86, 'min_samples_leaf': 3, 'min_samples_split': 22}\n",
      "[I 2023-08-28 10:39:49,768] Trial 8 finished with value: 0.8144670050761421 and parameters: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 8 finished.\n",
      "Best value after trial 8: 0.814\n",
      "Best params after trial 8: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:50,468] Trial 9 finished with value: 0.7991557028902931 and parameters: {'max_depth': 4, 'n_estimators': 103, 'min_samples_leaf': 2, 'min_samples_split': 9}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 9 finished.\n",
      "Best value after trial 9: 0.814\n",
      "Best params after trial 9: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:50,934] Trial 10 finished with value: 0.8062985600331503 and parameters: {'max_depth': 5, 'n_estimators': 58, 'min_samples_leaf': 1, 'min_samples_split': 32}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 10 finished.\n",
      "Best value after trial 10: 0.814\n",
      "Best params after trial 10: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:51,423] Trial 11 finished with value: 0.8063089195068891 and parameters: {'max_depth': 6, 'n_estimators': 61, 'min_samples_leaf': 1, 'min_samples_split': 17}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 11 finished.\n",
      "Best value after trial 11: 0.814\n",
      "Best params after trial 11: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:52,364] Trial 12 finished with value: 0.8052833316067544 and parameters: {'max_depth': 6, 'n_estimators': 143, 'min_samples_leaf': 3, 'min_samples_split': 18}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 12 finished.\n",
      "Best value after trial 12: 0.814\n",
      "Best params after trial 12: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:52,940] Trial 13 finished with value: 0.8134310577022686 and parameters: {'max_depth': 6, 'n_estimators': 76, 'min_samples_leaf': 2, 'min_samples_split': 17}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 13 finished.\n",
      "Best value after trial 13: 0.814\n",
      "Best params after trial 13: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:53,921] Trial 14 finished with value: 0.8093546047860768 and parameters: {'max_depth': 6, 'n_estimators': 149, 'min_samples_leaf': 1, 'min_samples_split': 15}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 14 finished.\n",
      "Best value after trial 14: 0.814\n",
      "Best params after trial 14: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:54,901] Trial 15 finished with value: 0.8062985600331503 and parameters: {'max_depth': 4, 'n_estimators': 157, 'min_samples_leaf': 2, 'min_samples_split': 22}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 15 finished.\n",
      "Best value after trial 15: 0.814\n",
      "Best params after trial 15: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:55,526] Trial 16 finished with value: 0.804262923443489 and parameters: {'max_depth': 6, 'n_estimators': 84, 'min_samples_leaf': 2, 'min_samples_split': 14}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 16 finished.\n",
      "Best value after trial 16: 0.814\n",
      "Best params after trial 16: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:56,358] Trial 17 finished with value: 0.8052729721330156 and parameters: {'max_depth': 5, 'n_estimators': 126, 'min_samples_leaf': 4, 'min_samples_split': 26}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 17 finished.\n",
      "Best value after trial 17: 0.814\n",
      "Best params after trial 17: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:57,637] Trial 18 finished with value: 0.8083290168859423 and parameters: {'max_depth': 6, 'n_estimators': 199, 'min_samples_leaf': 2, 'min_samples_split': 19}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 18 finished.\n",
      "Best value after trial 18: 0.814\n",
      "Best params after trial 18: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:58,670] Trial 19 finished with value: 0.8134362374391382 and parameters: {'max_depth': 4, 'n_estimators': 167, 'min_samples_leaf': 6, 'min_samples_split': 13}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 19 finished.\n",
      "Best value after trial 19: 0.814\n",
      "Best params after trial 19: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:39:59,663] Trial 20 finished with value: 0.79713560551124 and parameters: {'max_depth': 3, 'n_estimators': 159, 'min_samples_leaf': 6, 'min_samples_split': 14}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 20 finished.\n",
      "Best value after trial 20: 0.814\n",
      "Best params after trial 20: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:00,711] Trial 21 finished with value: 0.808339376359681 and parameters: {'max_depth': 4, 'n_estimators': 166, 'min_samples_leaf': 6, 'min_samples_split': 12}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 21 finished.\n",
      "Best value after trial 21: 0.814\n",
      "Best params after trial 21: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:01,910] Trial 22 finished with value: 0.8042525639697503 and parameters: {'max_depth': 4, 'n_estimators': 199, 'min_samples_leaf': 7, 'min_samples_split': 20}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 22 finished.\n",
      "Best value after trial 22: 0.814\n",
      "Best params after trial 22: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:02,768] Trial 23 finished with value: 0.8022272868538277 and parameters: {'max_depth': 5, 'n_estimators': 129, 'min_samples_leaf': 6, 'min_samples_split': 15}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 23 finished.\n",
      "Best value after trial 23: 0.814\n",
      "Best params after trial 23: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:03,840] Trial 24 finished with value: 0.807308608722677 and parameters: {'max_depth': 5, 'n_estimators': 79, 'min_samples_leaf': 1, 'min_samples_split': 17}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 24 finished.\n",
      "Best value after trial 24: 0.814\n",
      "Best params after trial 24: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:04,863] Trial 25 finished with value: 0.7940536620739665 and parameters: {'max_depth': 3, 'n_estimators': 50, 'min_samples_leaf': 4, 'min_samples_split': 26}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 25 finished.\n",
      "Best value after trial 25: 0.814\n",
      "Best params after trial 25: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:06,807] Trial 26 finished with value: 0.8022169273800891 and parameters: {'max_depth': 7, 'n_estimators': 165, 'min_samples_leaf': 7, 'min_samples_split': 12}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 26 finished.\n",
      "Best value after trial 26: 0.814\n",
      "Best params after trial 26: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:08,209] Trial 27 finished with value: 0.808329016885942 and parameters: {'max_depth': 4, 'n_estimators': 146, 'min_samples_leaf': 3, 'min_samples_split': 24}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 27 finished.\n",
      "Best value after trial 27: 0.814\n",
      "Best params after trial 27: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:09,929] Trial 28 finished with value: 0.8001761110535586 and parameters: {'max_depth': 6, 'n_estimators': 185, 'min_samples_leaf': 8, 'min_samples_split': 12}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 28 finished.\n",
      "Best value after trial 28: 0.814\n",
      "Best params after trial 28: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:11,027] Trial 29 finished with value: 0.8062985600331503 and parameters: {'max_depth': 3, 'n_estimators': 117, 'min_samples_leaf': 2, 'min_samples_split': 7}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 29 finished.\n",
      "Best value after trial 29: 0.814\n",
      "Best params after trial 29: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:12,731] Trial 30 finished with value: 0.8083497358334197 and parameters: {'max_depth': 7, 'n_estimators': 174, 'min_samples_leaf': 1, 'min_samples_split': 20}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 30 finished.\n",
      "Best value after trial 30: 0.814\n",
      "Best params after trial 30: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:13,631] Trial 31 finished with value: 0.8083445560965503 and parameters: {'max_depth': 7, 'n_estimators': 86, 'min_samples_leaf': 3, 'min_samples_split': 22}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 31 finished.\n",
      "Best value after trial 31: 0.814\n",
      "Best params after trial 31: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:14,390] Trial 32 finished with value: 0.8113954211126074 and parameters: {'max_depth': 7, 'n_estimators': 73, 'min_samples_leaf': 3, 'min_samples_split': 29}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 32 finished.\n",
      "Best value after trial 32: 0.814\n",
      "Best params after trial 32: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:15,453] Trial 33 finished with value: 0.8093649642598155 and parameters: {'max_depth': 7, 'n_estimators': 94, 'min_samples_leaf': 2, 'min_samples_split': 23}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 33 finished.\n",
      "Best value after trial 33: 0.814\n",
      "Best params after trial 33: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:16,223] Trial 34 finished with value: 0.8032321558064851 and parameters: {'max_depth': 6, 'n_estimators': 69, 'min_samples_leaf': 5, 'min_samples_split': 16}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 34 finished.\n",
      "Best value after trial 34: 0.814\n",
      "Best params after trial 34: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:17,983] Trial 35 finished with value: 0.808339376359681 and parameters: {'max_depth': 7, 'n_estimators': 184, 'min_samples_leaf': 4, 'min_samples_split': 2}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 35 finished.\n",
      "Best value after trial 35: 0.814\n",
      "Best params after trial 35: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:18,931] Trial 36 finished with value: 0.8124054698021341 and parameters: {'max_depth': 7, 'n_estimators': 92, 'min_samples_leaf': 3, 'min_samples_split': 20}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 36 finished.\n",
      "Best value after trial 36: 0.814\n",
      "Best params after trial 36: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:20,314] Trial 37 finished with value: 0.8062933802962811 and parameters: {'max_depth': 6, 'n_estimators': 138, 'min_samples_leaf': 5, 'min_samples_split': 11}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 37 finished.\n",
      "Best value after trial 37: 0.814\n",
      "Best params after trial 37: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:21,100] Trial 38 finished with value: 0.8103801926862116 and parameters: {'max_depth': 7, 'n_estimators': 67, 'min_samples_leaf': 2, 'min_samples_split': 24}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 38 finished.\n",
      "Best value after trial 38: 0.814\n",
      "Best params after trial 38: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:22,256] Trial 39 finished with value: 0.8103750129493422 and parameters: {'max_depth': 5, 'n_estimators': 115, 'min_samples_leaf': 1, 'min_samples_split': 18}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 39 finished.\n",
      "Best value after trial 39: 0.814\n",
      "Best params after trial 39: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:23,343] Trial 40 finished with value: 0.8032476950170931 and parameters: {'max_depth': 5, 'n_estimators': 102, 'min_samples_leaf': 4, 'min_samples_split': 8}. Best is trial 8 with value: 0.8144670050761421.\n",
      "\n",
      "Trial 40 finished.\n",
      "Best value after trial 40: 0.814\n",
      "Best params after trial 40: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:24,283] Trial 41 finished with value: 0.8165026416658033 and parameters: {'max_depth': 7, 'n_estimators': 88, 'min_samples_leaf': 3, 'min_samples_split': 20}. Best is trial 41 with value: 0.8165026416658033.\n",
      "\n",
      "Trial 41 finished.\n",
      "Best value after trial 41: 0.817\n",
      "Best params after trial 41: {'max_depth': 7, 'n_estimators': 88, 'min_samples_leaf': 3, 'min_samples_split': 20}\n",
      "[I 2023-08-28 10:40:25,311] Trial 42 finished with value: 0.8062933802962808 and parameters: {'max_depth': 7, 'n_estimators': 95, 'min_samples_leaf': 3, 'min_samples_split': 20}. Best is trial 41 with value: 0.8165026416658033.\n",
      "\n",
      "Trial 42 finished.\n",
      "Best value after trial 42: 0.817\n",
      "Best params after trial 42: {'max_depth': 7, 'n_estimators': 88, 'min_samples_leaf': 3, 'min_samples_split': 20}\n",
      "[I 2023-08-28 10:40:26,230] Trial 43 finished with value: 0.8093546047860768 and parameters: {'max_depth': 7, 'n_estimators': 78, 'min_samples_leaf': 2, 'min_samples_split': 16}. Best is trial 41 with value: 0.8165026416658033.\n",
      "\n",
      "Trial 43 finished.\n",
      "Best value after trial 43: 0.817\n",
      "Best params after trial 43: {'max_depth': 7, 'n_estimators': 88, 'min_samples_leaf': 3, 'min_samples_split': 20}\n",
      "[I 2023-08-28 10:40:27,006] Trial 44 finished with value: 0.8185486377292033 and parameters: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 44 finished.\n",
      "Best value after trial 44: 0.819\n",
      "Best params after trial 44: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:27,656] Trial 45 finished with value: 0.805278151869885 and parameters: {'max_depth': 6, 'n_estimators': 51, 'min_samples_leaf': 1, 'min_samples_split': 14}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 45 finished.\n",
      "Best value after trial 45: 0.819\n",
      "Best params after trial 45: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:28,391] Trial 46 finished with value: 0.8103750129493422 and parameters: {'max_depth': 7, 'n_estimators': 59, 'min_samples_leaf': 1, 'min_samples_split': 18}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 46 finished.\n",
      "Best value after trial 46: 0.819\n",
      "Best params after trial 46: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:29,187] Trial 47 finished with value: 0.8113902413757381 and parameters: {'max_depth': 7, 'n_estimators': 65, 'min_samples_leaf': 2, 'min_samples_split': 16}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 47 finished.\n",
      "Best value after trial 47: 0.819\n",
      "Best params after trial 47: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:30,692] Trial 48 finished with value: 0.811400600849477 and parameters: {'max_depth': 6, 'n_estimators': 152, 'min_samples_leaf': 1, 'min_samples_split': 13}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 48 finished.\n",
      "Best value after trial 48: 0.819\n",
      "Best params after trial 48: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:31,490] Trial 49 finished with value: 0.8124054698021341 and parameters: {'max_depth': 6, 'n_estimators': 73, 'min_samples_leaf': 2, 'min_samples_split': 22}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 49 finished.\n",
      "Best value after trial 49: 0.819\n",
      "Best params after trial 49: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:33,254] Trial 50 finished with value: 0.8134465969128769 and parameters: {'max_depth': 7, 'n_estimators': 175, 'min_samples_leaf': 1, 'min_samples_split': 4}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 50 finished.\n",
      "Best value after trial 50: 0.819\n",
      "Best params after trial 50: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:36,057] Trial 51 finished with value: 0.8103905521599504 and parameters: {'max_depth': 7, 'n_estimators': 177, 'min_samples_leaf': 1, 'min_samples_split': 4}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 51 finished.\n",
      "Best value after trial 51: 0.819\n",
      "Best params after trial 51: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:38,295] Trial 52 finished with value: 0.8114006008494767 and parameters: {'max_depth': 7, 'n_estimators': 192, 'min_samples_leaf': 1, 'min_samples_split': 19}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 52 finished.\n",
      "Best value after trial 52: 0.819\n",
      "Best params after trial 52: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:40,378] Trial 53 finished with value: 0.810385372423081 and parameters: {'max_depth': 7, 'n_estimators': 173, 'min_samples_leaf': 1, 'min_samples_split': 10}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 53 finished.\n",
      "Best value after trial 53: 0.819\n",
      "Best params after trial 53: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:42,407] Trial 54 finished with value: 0.8103801926862115 and parameters: {'max_depth': 4, 'n_estimators': 166, 'min_samples_leaf': 2, 'min_samples_split': 5}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 54 finished.\n",
      "Best value after trial 54: 0.819\n",
      "Best params after trial 54: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:44,235] Trial 55 finished with value: 0.8144670050761421 and parameters: {'max_depth': 7, 'n_estimators': 156, 'min_samples_leaf': 1, 'min_samples_split': 21}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 55 finished.\n",
      "Best value after trial 55: 0.819\n",
      "Best params after trial 55: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:45,615] Trial 56 finished with value: 0.8073137884595463 and parameters: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 6, 'min_samples_split': 21}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 56 finished.\n",
      "Best value after trial 56: 0.819\n",
      "Best params after trial 56: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:46,750] Trial 57 finished with value: 0.808339376359681 and parameters: {'max_depth': 7, 'n_estimators': 139, 'min_samples_leaf': 1, 'min_samples_split': 24}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 57 finished.\n",
      "Best value after trial 57: 0.819\n",
      "Best params after trial 57: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:47,938] Trial 58 finished with value: 0.8052885113436238 and parameters: {'max_depth': 7, 'n_estimators': 170, 'min_samples_leaf': 1, 'min_samples_split': 18}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 58 finished.\n",
      "Best value after trial 58: 0.819\n",
      "Best params after trial 58: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:48,847] Trial 59 finished with value: 0.808339376359681 and parameters: {'max_depth': 7, 'n_estimators': 132, 'min_samples_leaf': 5, 'min_samples_split': 21}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 59 finished.\n",
      "Best value after trial 59: 0.819\n",
      "Best params after trial 59: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:49,801] Trial 60 finished with value: 0.8002020097379055 and parameters: {'max_depth': 3, 'n_estimators': 152, 'min_samples_leaf': 8, 'min_samples_split': 3}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 60 finished.\n",
      "Best value after trial 60: 0.819\n",
      "Best params after trial 60: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:50,890] Trial 61 finished with value: 0.808339376359681 and parameters: {'max_depth': 6, 'n_estimators': 165, 'min_samples_leaf': 1, 'min_samples_split': 19}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 61 finished.\n",
      "Best value after trial 61: 0.819\n",
      "Best params after trial 61: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:51,958] Trial 62 finished with value: 0.8083290168859423 and parameters: {'max_depth': 7, 'n_estimators': 159, 'min_samples_leaf': 2, 'min_samples_split': 16}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 62 finished.\n",
      "Best value after trial 62: 0.819\n",
      "Best params after trial 62: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:53,137] Trial 63 finished with value: 0.8103698332124727 and parameters: {'max_depth': 6, 'n_estimators': 180, 'min_samples_leaf': 2, 'min_samples_split': 17}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 63 finished.\n",
      "Best value after trial 63: 0.819\n",
      "Best params after trial 63: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:54,383] Trial 64 finished with value: 0.808339376359681 and parameters: {'max_depth': 7, 'n_estimators': 191, 'min_samples_leaf': 1, 'min_samples_split': 21}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 64 finished.\n",
      "Best value after trial 64: 0.819\n",
      "Best params after trial 64: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:54,825] Trial 65 finished with value: 0.8032217963327464 and parameters: {'max_depth': 4, 'n_estimators': 55, 'min_samples_leaf': 2, 'min_samples_split': 28}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 65 finished.\n",
      "Best value after trial 65: 0.819\n",
      "Best params after trial 65: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:55,433] Trial 66 finished with value: 0.8124261887496115 and parameters: {'max_depth': 7, 'n_estimators': 80, 'min_samples_leaf': 1, 'min_samples_split': 15}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 66 finished.\n",
      "Best value after trial 66: 0.819\n",
      "Best params after trial 66: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:56,293] Trial 67 finished with value: 0.8062933802962811 and parameters: {'max_depth': 6, 'n_estimators': 123, 'min_samples_leaf': 7, 'min_samples_split': 23}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 67 finished.\n",
      "Best value after trial 67: 0.819\n",
      "Best params after trial 67: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:57,265] Trial 68 finished with value: 0.805278151869885 and parameters: {'max_depth': 7, 'n_estimators': 144, 'min_samples_leaf': 3, 'min_samples_split': 17}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 68 finished.\n",
      "Best value after trial 68: 0.819\n",
      "Best params after trial 68: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:58,284] Trial 69 finished with value: 0.8124158292758729 and parameters: {'max_depth': 5, 'n_estimators': 160, 'min_samples_leaf': 2, 'min_samples_split': 19}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 69 finished.\n",
      "Best value after trial 69: 0.819\n",
      "Best params after trial 69: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:40:59,495] Trial 70 finished with value: 0.8083445560965503 and parameters: {'max_depth': 7, 'n_estimators': 190, 'min_samples_leaf': 1, 'min_samples_split': 32}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 70 finished.\n",
      "Best value after trial 70: 0.819\n",
      "Best params after trial 70: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:00,039] Trial 71 finished with value: 0.8134310577022686 and parameters: {'max_depth': 7, 'n_estimators': 63, 'min_samples_leaf': 1, 'min_samples_split': 14}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 71 finished.\n",
      "Best value after trial 71: 0.819\n",
      "Best params after trial 71: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:00,559] Trial 72 finished with value: 0.8103750129493422 and parameters: {'max_depth': 7, 'n_estimators': 64, 'min_samples_leaf': 1, 'min_samples_split': 9}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 72 finished.\n",
      "Best value after trial 72: 0.819\n",
      "Best params after trial 72: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:01,021] Trial 73 finished with value: 0.8093546047860769 and parameters: {'max_depth': 7, 'n_estimators': 54, 'min_samples_leaf': 1, 'min_samples_split': 13}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 73 finished.\n",
      "Best value after trial 73: 0.819\n",
      "Best params after trial 73: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:01,600] Trial 74 finished with value: 0.808339376359681 and parameters: {'max_depth': 7, 'n_estimators': 74, 'min_samples_leaf': 2, 'min_samples_split': 14}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 74 finished.\n",
      "Best value after trial 74: 0.819\n",
      "Best params after trial 74: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:02,135] Trial 75 finished with value: 0.8113954211126074 and parameters: {'max_depth': 6, 'n_estimators': 69, 'min_samples_leaf': 1, 'min_samples_split': 17}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 75 finished.\n",
      "Best value after trial 75: 0.819\n",
      "Best params after trial 75: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:02,776] Trial 76 finished with value: 0.8103801926862116 and parameters: {'max_depth': 7, 'n_estimators': 85, 'min_samples_leaf': 2, 'min_samples_split': 15}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 76 finished.\n",
      "Best value after trial 76: 0.819\n",
      "Best params after trial 76: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:03,916] Trial 77 finished with value: 0.8063140992437583 and parameters: {'max_depth': 7, 'n_estimators': 170, 'min_samples_leaf': 1, 'min_samples_split': 7}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 77 finished.\n",
      "Best value after trial 77: 0.819\n",
      "Best params after trial 77: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:04,428] Trial 78 finished with value: 0.8073189681964156 and parameters: {'max_depth': 7, 'n_estimators': 63, 'min_samples_leaf': 6, 'min_samples_split': 11}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 78 finished.\n",
      "Best value after trial 78: 0.819\n",
      "Best params after trial 78: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:04,896] Trial 79 finished with value: 0.8062882005594115 and parameters: {'max_depth': 6, 'n_estimators': 57, 'min_samples_leaf': 4, 'min_samples_split': 19}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 79 finished.\n",
      "Best value after trial 79: 0.819\n",
      "Best params after trial 79: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:05,884] Trial 80 finished with value: 0.8103801926862116 and parameters: {'max_depth': 5, 'n_estimators': 154, 'min_samples_leaf': 2, 'min_samples_split': 13}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 80 finished.\n",
      "Best value after trial 80: 0.819\n",
      "Best params after trial 80: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:06,380] Trial 81 finished with value: 0.8052833316067544 and parameters: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 15}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 81 finished.\n",
      "Best value after trial 81: 0.819\n",
      "Best params after trial 81: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:06,997] Trial 82 finished with value: 0.807324147933285 and parameters: {'max_depth': 7, 'n_estimators': 81, 'min_samples_leaf': 1, 'min_samples_split': 18}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 82 finished.\n",
      "Best value after trial 82: 0.819\n",
      "Best params after trial 82: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:07,667] Trial 83 finished with value: 0.8052936910804931 and parameters: {'max_depth': 7, 'n_estimators': 90, 'min_samples_leaf': 1, 'min_samples_split': 15}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 83 finished.\n",
      "Best value after trial 83: 0.819\n",
      "Best params after trial 83: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:08,383] Trial 84 finished with value: 0.8124158292758727 and parameters: {'max_depth': 7, 'n_estimators': 99, 'min_samples_leaf': 1, 'min_samples_split': 20}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 84 finished.\n",
      "Best value after trial 84: 0.819\n",
      "Best params after trial 84: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:09,140] Trial 85 finished with value: 0.8083341966228115 and parameters: {'max_depth': 7, 'n_estimators': 108, 'min_samples_leaf': 3, 'min_samples_split': 16}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 85 finished.\n",
      "Best value after trial 85: 0.819\n",
      "Best params after trial 85: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:09,734] Trial 86 finished with value: 0.8114109603232155 and parameters: {'max_depth': 7, 'n_estimators': 76, 'min_samples_leaf': 1, 'min_samples_split': 11}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 86 finished.\n",
      "Best value after trial 86: 0.819\n",
      "Best params after trial 86: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:10,338] Trial 87 finished with value: 0.8073189681964156 and parameters: {'max_depth': 7, 'n_estimators': 81, 'min_samples_leaf': 7, 'min_samples_split': 23}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 87 finished.\n",
      "Best value after trial 87: 0.819\n",
      "Best params after trial 87: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:10,962] Trial 88 finished with value: 0.8042422044960116 and parameters: {'max_depth': 4, 'n_estimators': 87, 'min_samples_leaf': 1, 'min_samples_split': 18}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 88 finished.\n",
      "Best value after trial 88: 0.819\n",
      "Best params after trial 88: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:11,502] Trial 89 finished with value: 0.8164871024551953 and parameters: {'max_depth': 7, 'n_estimators': 69, 'min_samples_leaf': 2, 'min_samples_split': 14}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 89 finished.\n",
      "Best value after trial 89: 0.819\n",
      "Best params after trial 89: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:12,036] Trial 90 finished with value: 0.811400600849477 and parameters: {'max_depth': 6, 'n_estimators': 69, 'min_samples_leaf': 2, 'min_samples_split': 21}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 90 finished.\n",
      "Best value after trial 90: 0.819\n",
      "Best params after trial 90: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:12,603] Trial 91 finished with value: 0.8134362374391382 and parameters: {'max_depth': 7, 'n_estimators': 72, 'min_samples_leaf': 1, 'min_samples_split': 12}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 91 finished.\n",
      "Best value after trial 91: 0.819\n",
      "Best params after trial 91: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:13,157] Trial 92 finished with value: 0.8134414171760074 and parameters: {'max_depth': 7, 'n_estimators': 70, 'min_samples_leaf': 2, 'min_samples_split': 10}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 92 finished.\n",
      "Best value after trial 92: 0.819\n",
      "Best params after trial 92: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:13,718] Trial 93 finished with value: 0.8093597845229462 and parameters: {'max_depth': 7, 'n_estimators': 71, 'min_samples_leaf': 3, 'min_samples_split': 12}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 93 finished.\n",
      "Best value after trial 93: 0.819\n",
      "Best params after trial 93: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:14,812] Trial 94 finished with value: 0.8124261887496115 and parameters: {'max_depth': 7, 'n_estimators': 163, 'min_samples_leaf': 2, 'min_samples_split': 8}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 94 finished.\n",
      "Best value after trial 94: 0.819\n",
      "Best params after trial 94: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:15,422] Trial 95 finished with value: 0.8052833316067544 and parameters: {'max_depth': 7, 'n_estimators': 77, 'min_samples_leaf': 2, 'min_samples_split': 11}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 95 finished.\n",
      "Best value after trial 95: 0.819\n",
      "Best params after trial 95: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:16,622] Trial 96 finished with value: 0.8042577437066196 and parameters: {'max_depth': 7, 'n_estimators': 181, 'min_samples_leaf': 4, 'min_samples_split': 13}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 96 finished.\n",
      "Best value after trial 96: 0.819\n",
      "Best params after trial 96: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:17,647] Trial 97 finished with value: 0.7879571117787216 and parameters: {'max_depth': 3, 'n_estimators': 170, 'min_samples_leaf': 3, 'min_samples_split': 10}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 97 finished.\n",
      "Best value after trial 97: 0.819\n",
      "Best params after trial 97: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:18,187] Trial 98 finished with value: 0.8093597845229462 and parameters: {'max_depth': 7, 'n_estimators': 65, 'min_samples_leaf': 2, 'min_samples_split': 5}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 98 finished.\n",
      "Best value after trial 98: 0.819\n",
      "Best params after trial 98: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "[I 2023-08-28 10:41:19,336] Trial 99 finished with value: 0.8093701439966849 and parameters: {'max_depth': 7, 'n_estimators': 175, 'min_samples_leaf': 2, 'min_samples_split': 22}. Best is trial 44 with value: 0.8185486377292033.\n",
      "\n",
      "Trial 99 finished.\n",
      "Best value after trial 99: 0.819\n",
      "Best params after trial 99: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def print_accuracy(accuracy, dataset_name):\n",
    "    print(f\"{dataset_name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# Obtain the best parameters and their corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "# Display the best parameters and their corresponding accuracy\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print_accuracy(best_accuracy, \"Best CV\")\n",
    "\n",
    "# Train the best model on the training data\n",
    "best_model = RandomForestClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and calculate the accuracy\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Display the test accuracy\n",
    "print_accuracy(test_accuracy, \"Testing\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6RsdF9nJCkF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689199069230,
     "user_tz": 240,
     "elapsed": 183,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "85f309ba-77a8-4720-991c-7d1dbf2ddf84",
    "ExecuteTime": {
     "end_time": "2023-08-28T14:41:19.545071Z",
     "start_time": "2023-08-28T14:41:19.443935Z"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 7, 'n_estimators': 60, 'min_samples_leaf': 1, 'min_samples_split': 18}\n",
      "Best CV Accuracy: 81.85%\n",
      "Testing Accuracy: 81.10%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Your Turn**\n",
    "\n",
    "- How do the CV accuracies of the grid search and Optuna compare? ______________\n",
    "- What differences do you notice in their testing accuracies? ______________\n",
    "- Which method completed faster, and why do you think this was the case? ______________\n",
    "\n",
    "Hyperparameter Tuning for Neural Networks\n",
    "\n",
    "One compelling use case for Bayesian Optimization is hyperparameter tuning for neural networks. Training these models can be time-consuming and their performance can be significantly affected by hyperparameters such as dropout rate, learning rate, weight decay, batch size, among others. Let's explore how we can optimize these parameters for a neural network.\n",
    "\n",
    "Our hyperparameters for this network will include:\n",
    "\n",
    "- The batch size utilized during training\n",
    "- The learning rate for the training process\n",
    "- The number of training epochs\n",
    "- The size of the hidden layer in the network."
   ],
   "metadata": {
    "id": "KfQzBH9VKUyU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's outside of the scope of this lab, but the code for our neural network is below. Thanks to our network class having fit and predict functions, we can actually reuse much of our code from the Random Forest example."
   ],
   "metadata": {
    "id": "pLPKZ119ZUHn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TitanicMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple two-layer network for the Titanic dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, learning_rate, epochs):\n",
    "        super(TitanicMLP, self).__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Define the forward pass layers\n",
    "        self.forward_pass = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform the forward pass.\n",
    "        \"\"\"\n",
    "        return self.forward_pass(x)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "\n",
    "        # Create tensors\n",
    "        X_tensor = torch.Tensor(X).float()\n",
    "        Y_tensor = torch.Tensor(y).float()\n",
    "\n",
    "        # Create DataLoader\n",
    "        train_dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(self.epochs):\n",
    "            for batch_idx, (features, target) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()  # reset gradients\n",
    "                outputs = self.forward(features)  # forward pass\n",
    "                loss = self.criterion(\n",
    "                    torch.squeeze(outputs), torch.squeeze(target)\n",
    "                )  # calculate loss\n",
    "                loss.backward()  # backpropagation\n",
    "                self.optimizer.step()  # update weights\n",
    "\n",
    "            # Print progress\n",
    "            if (epoch + 1) % 10 == 0 and epoch != 0:\n",
    "                print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class of the input data X.\n",
    "        \"\"\"\n",
    "        self.eval()  # switch to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.Tensor(X)\n",
    "            y_pred = torch.sigmoid(\n",
    "                self.forward(X_tensor)\n",
    "            )  # apply sigmoid for binary output\n",
    "            y_pred = (\n",
    "                torch.round(y_pred).squeeze().numpy()\n",
    "            )  # round to nearest integer (0 or 1) and convert to numpy array\n",
    "        return y_pred\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Your Turn**\n",
    "\n",
    "- Currently, the Hyperparameter search has some placeholder values passed in. Replace these fixed values with Optuna variables to search the space.\n",
    "- Examine the scores produced for the various parameter configurations tested by Optuna. Do they exhibit similar performance, or do they significantly influence the model's effectiveness?\n",
    "\n",
    "Remember, the purpose of hyperparameter tuning is to optimize the model's performance, and sometimes even a minor change in parameters can lead to substantial improvement. So, it's crucial to pay close attention to the scores and make adjustments as necessary.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def optuna_mlp_function(trial):\n",
    "    # Define the hyperparameters\n",
    "    hyperparameters = {\n",
    "        \"input_dim\": trial.suggest_categorical(\n",
    "            \"input_dim\", [X_train.shape[1]]\n",
    "        ),  # Fixed parameter, no need to include in the trial\n",
    "        \"hidden_dim\": 1,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"epochs\": 10,\n",
    "    }\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = TitanicMLP(**hyperparameters)\n",
    "    scores = []\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_index, val_index in kfold.split(X_train, y_train):\n",
    "        X_train_fold = X_train[train_index]\n",
    "        y_train_fold = y_train.values[train_index]\n",
    "        X_val_fold = X_train[val_index]\n",
    "        y_val_fold = y_train.values[val_index]\n",
    "\n",
    "        # Fit the model and predict on the validation data\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "\n",
    "        # Append the accuracy score to the list of scores\n",
    "        scores.append(accuracy_score(y_val_fold, y_pred))\n",
    "\n",
    "    # Return the mean cross-validation accuracy\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Initialize the Optuna study and set the optimization direction\n",
    "mlp_study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Run the optimization\n",
    "mlp_study.optimize(\n",
    "    optuna_mlp_function,\n",
    "    n_trials=100,\n",
    "    callbacks=[print_callback],\n",
    "    show_progress_bar=True,\n",
    "    gc_after_trial=True,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e0aef6ccaf6d43e1b5c400b2307a265e",
      "f21470133c574f5c9d0707c979038cbf",
      "ecf72f14216949e3b93f5f0f78f9baba",
      "6e6a13c6cb6640d2b874207cb29d487e",
      "7ea0dc58b97e422283f5822274fa68df",
      "41c5428891fb4b9e8e00545c027a4794",
      "171232bb06a841698fd3af2bef742cb7",
      "cf6ad7ae768647b6b317ca2266c9f784",
      "02f8ea4fe50c495cb38378ca1e16dc6b",
      "7c2094a8784c452dbf4bed4c449e1471",
      "6a85def097714d12943770ae703d7000"
     ]
    },
    "id": "JNAl8udWXi8v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689200358759,
     "user_tz": 240,
     "elapsed": 1286587,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "d139da5c-1812-460a-a91a-9d38284391d5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "best_params = mlp_study.best_params\n",
    "best_accuracy = mlp_study.best_value\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print_accuracy(best_accuracy, \"Best CV\")\n",
    "\n",
    "best_model = TitanicMLP(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print_accuracy(test_accuracy, \"Testing\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XU5CsRnAa4N9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689200362022,
     "user_tz": 240,
     "elapsed": 3265,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     }
    },
    "outputId": "34f5c470-8cb0-4152-93c1-a5b6277475a8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Your Turn**\n",
    "\n",
    "Besides the parameters we searched for above, can you think of other hyperparameters that could be tuned in a Neural Network?\n",
    "\n",
    "Hint: There are several aspects of a Neural Network's architecture and training process that can be adjusted. These could include the type of optimizer used, the activation functions applied, the initialization method for weights, and much more. Think about the various components that make up a Neural Network and how adjusting them might impact the model's performance."
   ],
   "metadata": {
    "id": "in1P8TDhF8jV"
   }
  }
 ]
}
