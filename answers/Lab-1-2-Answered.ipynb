{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIPYMpobxpaD"
   },
   "source": [
    "Machine Learning operates by solving an optimization problem to determine the parameters of a function that best fits the data. However, some parameters - known as hyperparameters - can't be learned through this process, as they set the model structure and guide the optimization procedure. Tuning these hyperparameters is a crucial part of model development and can greatly impact model performance.\n",
    "\n",
    "Hyperparameter tuning refers to the task of discovering the optimal hyperparameters for a given model and dataset. This process is a key stage in the machine learning workflow. Nevertheless, it poses a challenging task due to its complex nature - there is no universal methodology that applies to all scenarios. The selection of the best hyperparameters relies heavily on the dataset at hand, the chosen model architecture, and the specific learning task. Therefore, identifying the ideal set of hyperparameters is not about finding a one-size-fits-all solution, but rather about employing a mix of intuition, systematic testing, and optimization techniques.\n",
    "\n",
    "In this lab, we will delve into the fundamentals of hyperparameter tuning, exploring methods such as Grid Search, Cross Validation, and Bayesian Optimization. Let's dive in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:09:34.922969Z",
     "start_time": "2023-08-28T18:09:34.919819Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Check if we are running on Google Colab, or locally\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:09:45.892079Z",
     "start_time": "2023-08-28T18:09:41.081600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    # Colab already has these installed\n",
    "    !pip install -q torch torchvision torchaudio numpy pandas matplotlib scikit-learn\n",
    "!pip install -q optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:09:49.573875Z",
     "start_time": "2023-08-28T18:09:45.897778Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65609,
     "status": "ok",
     "timestamp": 1689198423116,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     },
     "user_tz": 240
    },
    "id": "MHB2yx2Gxpop",
    "outputId": "36494fc7-062f-494e-b062-2c7c91e865ea"
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# Import libraries for data handling and manipulation\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_validate,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "import optuna\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28XanXRqznHx"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this lab, we'll be using the Titanic dataset. To prepare our dataset for the subsequent learning tasks, we'll have to perform the following steps:\n",
    "\n",
    "1. Discard irrelevant columns: Some columns may not contribute to the model's predictive performance and can be removed.\n",
    "2. Adjust data types of certain columns: Some columns may have incorrect data types that need to be fixed for proper analysis.\n",
    "3. Split the dataset into Training and Test sets: This ensures we have a separate dataset (Test set) to evaluate our model's performance.\n",
    "4. Handle missing values: We need to impute or fill in missing values to avoid complications during the learning process.\n",
    "5. Scale the data: It's necessary to standardize our data to ensure all features have equal importance in model training.\n",
    "\n",
    "We'll be carrying out all these steps in the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zabour, Miss. Hileni</td>\n",
       "      <td>female</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zabour, Miss. Thamine</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr. Mapriededer</td>\n",
       "      <td>male</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2656</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr. Ortin</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2670</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimmerman, Mr. Leo</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315082</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass survived                                             name  \\\n",
       "0          1        1                    Allen, Miss. Elisabeth Walton   \n",
       "1          1        1                   Allison, Master. Hudson Trevor   \n",
       "2          1        0                     Allison, Miss. Helen Loraine   \n",
       "3          1        0             Allison, Mr. Hudson Joshua Creighton   \n",
       "4          1        0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)   \n",
       "...      ...      ...                                              ...   \n",
       "1304       3        0                             Zabour, Miss. Hileni   \n",
       "1305       3        0                            Zabour, Miss. Thamine   \n",
       "1306       3        0                        Zakarian, Mr. Mapriededer   \n",
       "1307       3        0                              Zakarian, Mr. Ortin   \n",
       "1308       3        0                               Zimmerman, Mr. Leo   \n",
       "\n",
       "         sex      age  sibsp  parch  ticket      fare    cabin embarked boat  \\\n",
       "0     female  29.0000      0      0   24160  211.3375       B5        S    2   \n",
       "1       male   0.9167      1      2  113781  151.5500  C22 C26        S   11   \n",
       "2     female   2.0000      1      2  113781  151.5500  C22 C26        S  NaN   \n",
       "3       male  30.0000      1      2  113781  151.5500  C22 C26        S  NaN   \n",
       "4     female  25.0000      1      2  113781  151.5500  C22 C26        S  NaN   \n",
       "...      ...      ...    ...    ...     ...       ...      ...      ...  ...   \n",
       "1304  female  14.5000      1      0    2665   14.4542      NaN        C  NaN   \n",
       "1305  female      NaN      1      0    2665   14.4542      NaN        C  NaN   \n",
       "1306    male  26.5000      0      0    2656    7.2250      NaN        C  NaN   \n",
       "1307    male  27.0000      0      0    2670    7.2250      NaN        C  NaN   \n",
       "1308    male  29.0000      0      0  315082    7.8750      NaN        S  NaN   \n",
       "\n",
       "       body                        home.dest  \n",
       "0       NaN                     St Louis, MO  \n",
       "1       NaN  Montreal, PQ / Chesterville, ON  \n",
       "2       NaN  Montreal, PQ / Chesterville, ON  \n",
       "3     135.0  Montreal, PQ / Chesterville, ON  \n",
       "4       NaN  Montreal, PQ / Chesterville, ON  \n",
       "...     ...                              ...  \n",
       "1304  328.0                              NaN  \n",
       "1305    NaN                              NaN  \n",
       "1306  304.0                              NaN  \n",
       "1307    NaN                              NaN  \n",
       "1308    NaN                              NaN  \n",
       "\n",
       "[1309 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_openml(\"titanic\", version=1, as_frame=True, parser=\"auto\").frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:09:49.606238Z",
     "start_time": "2023-08-28T18:09:49.570691Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1689198424388,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     },
     "user_tz": 240
    },
    "id": "YUNddJ_Ez2gU",
    "outputId": "09e0c562-fe79-47c1-bc41-d88caac6df82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 981 training data points and 328 testing points\n",
      "There are 6 features in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Fetch data\n",
    "data = fetch_openml(\"titanic\", version=1, as_frame=True, parser=\"auto\").frame\n",
    "\n",
    "# Select features\n",
    "unimportant_cols = [\"name\", \"ticket\", \"cabin\", \"embarked\", \"boat\", \"body\", \"home.dest\"]\n",
    "data = data.drop(unimportant_cols, axis=1)\n",
    "\n",
    "# Encode categorical features and convert relevant columns to numeric data type\n",
    "label_encoder = LabelEncoder()  # Encoder for categorical features\n",
    "data[\"sex\"] = label_encoder.fit_transform(data[\"sex\"])\n",
    "data[\"survived\"] = data[\"survived\"].astype(\"int\")\n",
    "\n",
    "# Split data into features and target\n",
    "target_data = data[\"survived\"]\n",
    "feature_data = data.drop(\"survived\", axis=1)\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_data, target_data, test_size=0.25, random_state=0\n",
    ")\n",
    "\n",
    "# Handle missing values with imputation\n",
    "imputer = SimpleImputer(\n",
    "    missing_values=np.nan, strategy=\"most_frequent\"\n",
    ")  # Imputer for handling missing values\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Print information about the final dataset\n",
    "print(\n",
    "    f\"There are {X_train.shape[0]} training data points and {X_test.shape[0]} testing points\"\n",
    ")\n",
    "print(f\"There are {X_train.shape[1]} features in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5VIfGvg5CJr"
   },
   "source": [
    "## Grid Search\n",
    "\n",
    "With our data ready, we can commence our exploration of hyperparameter tuning. Our initial approach will be grid search, a method that involves constructing a grid of potential hyperparameters and systematically examining the model's performance for each combination. To attain a reliable measure of model performance, grid search is often combined with K-Fold cross-validation. The Grid Search CV process involves:\n",
    "\n",
    "1. Hyperparameter grid definition: Identify the hyperparameters to be tuned and designate possible values for each one. This forms a grid, where each point represents a unique set of hyperparameters.\n",
    "2. Cross-validation across folds: For each unique set of hyperparameters, execute a K-Fold Cross-validation on your model and calculate the average error.\n",
    "3. Hyperparameters selection: Opt for the hyperparameters that result in the best performance (i.e., the lowest error).\n",
    "\n",
    "Let's delve into the impact of hyperparameter tuning using a simple Random Forest Classifier in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:11:01.444944Z",
     "start_time": "2023-08-28T18:09:50.268138Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 519453,
     "status": "ok",
     "timestamp": 1689198943839,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     },
     "user_tz": 240
    },
    "id": "3-t1k64t-O2U",
    "outputId": "419c2834-552c-4489-b74b-807b112d8719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up a Random Forest Classifier...\n",
      "Defining hyperparameters for Grid Search...\n",
      "Setting up Grid Search with 5-fold Cross Validation...\n",
      "Running Grid Search (This may take a while)...\n",
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "Grid Search completed in 59 seconds\n",
      "Best Parameters: {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 150}\n",
      "Best CV Accuracy: 81.65%\n",
      "Evaluating model on test data...\n",
      "Testing Accuracy: 81.10%\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up a Random Forest Classifier...\")\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "print(\"Defining hyperparameters for Grid Search...\")\n",
    "hyperparameter_search = {\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],  # Max Depth of each individual tree\n",
    "    \"n_estimators\": [50, 100, 150, 200],  # Number of trees generated\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8],  # Minimum number of samples found in a leaf\n",
    "    \"min_samples_split\": [2, 4, 8, 16, 32],  # Minimum samples required for a split\n",
    "}\n",
    "\n",
    "print(\"Setting up Grid Search with 5-fold Cross Validation...\")\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=hyperparameter_search,\n",
    "    scoring=make_scorer(accuracy_score, greater_is_better=True),\n",
    "    verbose=1,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "print(\"Running Grid Search (This may take a while)...\")\n",
    "start_time = time()\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "\n",
    "print(f\"Grid Search completed in {end_time - start_time:.0f} seconds\")\n",
    "\n",
    "print(f\"Best Parameters: {grid_search_cv.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {grid_search_cv.best_score_ * 100:.2f}%\")\n",
    "\n",
    "print(\"Evaluating model on test data...\")\n",
    "clf = grid_search_cv.best_estimator_\n",
    "test_predictions = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iznvVdvCA7vj"
   },
   "source": [
    "## Advanced Parameter Searching\n",
    "\n",
    "While Grid Search proves effective in many scenarios, its major limitation is its computational demand. The number of models to be trained escalates exponentially with each additional hyperparameter. In our previous example, we had to train a model over five thousand times due to the 1024 combinations ($4^5$) and 5-fold cross-validation. This approach might be feasible for simpler models like Random Forests or Linear/Logistic regression, but it becomes prohibitively time-consuming for deep learning models or when dealing with a large search space.\n",
    "\n",
    "## Introducing Bayesian Optimization\n",
    "\n",
    "An alternative hyperparameter tuning technique, Bayesian Optimization, can help mitigate these computational concerns. It's a sequential, model-based optimization method used to find the optimal hyperparameters for a given machine learning model. This technique combines Bayesian inference and optimization to identify promising regions for evaluation, utilizing a surrogate model to approximate the performance of our primary model concerning its hyperparameters.\n",
    "\n",
    "One of the key advantages of Bayesian optimization is its efficient exploration of the hyperparameter space, which provides a significant edge over exhaustive search methods like grid search. It intelligently selects new configurations based on predictions from the surrogate model, thus converging to the optimal hyperparameters more rapidly and with fewer evaluations.\n",
    "\n",
    "Next, let's apply Bayesian Optimization for parameter search in our Random Forest model. We'll leverage Optuna, a hyperparameter optimization library that encapsulates this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:12:51.189453Z",
     "start_time": "2023-08-28T18:11:01.446422Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f6d84beb6f8e477a9c0d45817accc8b0",
      "3996aef1fc0f4b7ea9a5f6dbaffd4fba",
      "330269805d30447895208d5c4f79e728",
      "adee0055ed694b0a9f643a489d3fb08a",
      "76b654fd1e0a4da8b4a3bb949c286086",
      "e05c7217178646a1b362f13e93d7fc00",
      "6f35d1788d3b498ca7dccc8072a36daf",
      "2d85108019624c6bb12a020175c24afe",
      "0cd81b6de72048c8961aa7778b653a0b",
      "9a08383cb3b24b129429c401fa4e8df4",
      "1b58e8e784a045e08d6605205d63150a"
     ]
    },
    "executionInfo": {
     "elapsed": 125228,
     "status": "ok",
     "timestamp": 1689199069057,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     },
     "user_tz": 240
    },
    "id": "nEDytL6uA4oU",
    "outputId": "8625709b-04be-468e-f957-c84f3972c85d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 15:15:41,745] A new study created in memory with name: no-name-807f3d20-710a-4232-865e-f13344c340a0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baa60af44dc4864835e9fa16b50c385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 15:15:42,875] Trial 0 finished with value: 0.8093597845229462 and parameters: {'max_depth': 7, 'n_estimators': 190, 'min_samples_leaf': 1, 'min_samples_split': 28}. Best is trial 0 with value: 0.8093597845229462.\n",
      "\n",
      "Trial 0 finished.\n",
      "Best value after trial 0: 0.809\n",
      "Best params after trial 0: {'max_depth': 7, 'n_estimators': 190, 'min_samples_leaf': 1, 'min_samples_split': 28}\n",
      "[I 2023-08-28 15:15:43,919] Trial 1 finished with value: 0.8103801926862116 and parameters: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 1 finished.\n",
      "Best value after trial 1: 0.810\n",
      "Best params after trial 1: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:45,006] Trial 2 finished with value: 0.8032321558064851 and parameters: {'max_depth': 4, 'n_estimators': 177, 'min_samples_leaf': 3, 'min_samples_split': 2}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 2 finished.\n",
      "Best value after trial 2: 0.810\n",
      "Best params after trial 2: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:45,444] Trial 3 finished with value: 0.8052833316067545 and parameters: {'max_depth': 7, 'n_estimators': 54, 'min_samples_leaf': 1, 'min_samples_split': 27}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 3 finished.\n",
      "Best value after trial 3: 0.810\n",
      "Best params after trial 3: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:46,040] Trial 4 finished with value: 0.8083238371490727 and parameters: {'max_depth': 5, 'n_estimators': 84, 'min_samples_leaf': 6, 'min_samples_split': 2}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 4 finished.\n",
      "Best value after trial 4: 0.810\n",
      "Best params after trial 4: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:46,979] Trial 5 finished with value: 0.8042681031803584 and parameters: {'max_depth': 7, 'n_estimators': 142, 'min_samples_leaf': 6, 'min_samples_split': 20}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 5 finished.\n",
      "Best value after trial 5: 0.810\n",
      "Best params after trial 5: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:47,934] Trial 6 finished with value: 0.8073086087226768 and parameters: {'max_depth': 4, 'n_estimators': 158, 'min_samples_leaf': 5, 'min_samples_split': 31}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 6 finished.\n",
      "Best value after trial 6: 0.810\n",
      "Best params after trial 6: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:48,901] Trial 7 finished with value: 0.804262923443489 and parameters: {'max_depth': 6, 'n_estimators': 150, 'min_samples_leaf': 4, 'min_samples_split': 15}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 7 finished.\n",
      "Best value after trial 7: 0.810\n",
      "Best params after trial 7: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:49,860] Trial 8 finished with value: 0.8062726613488035 and parameters: {'max_depth': 4, 'n_estimators': 153, 'min_samples_leaf': 8, 'min_samples_split': 30}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 8 finished.\n",
      "Best value after trial 8: 0.810\n",
      "Best params after trial 8: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:50,294] Trial 9 finished with value: 0.808339376359681 and parameters: {'max_depth': 7, 'n_estimators': 54, 'min_samples_leaf': 3, 'min_samples_split': 12}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 9 finished.\n",
      "Best value after trial 9: 0.810\n",
      "Best params after trial 9: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:50,991] Trial 10 finished with value: 0.785931834662799 and parameters: {'max_depth': 3, 'n_estimators': 109, 'min_samples_leaf': 8, 'min_samples_split': 21}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 10 finished.\n",
      "Best value after trial 10: 0.810\n",
      "Best params after trial 10: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:52,222] Trial 11 finished with value: 0.8052833316067544 and parameters: {'max_depth': 6, 'n_estimators': 194, 'min_samples_leaf': 1, 'min_samples_split': 25}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 11 finished.\n",
      "Best value after trial 11: 0.810\n",
      "Best params after trial 11: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:53,470] Trial 12 finished with value: 0.8063140992437585 and parameters: {'max_depth': 6, 'n_estimators': 193, 'min_samples_leaf': 3, 'min_samples_split': 11}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 12 finished.\n",
      "Best value after trial 12: 0.810\n",
      "Best params after trial 12: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:54,288] Trial 13 finished with value: 0.8022221071169584 and parameters: {'max_depth': 7, 'n_estimators': 120, 'min_samples_leaf': 6, 'min_samples_split': 23}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 13 finished.\n",
      "Best value after trial 13: 0.810\n",
      "Best params after trial 13: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:55,425] Trial 14 finished with value: 0.8093649642598155 and parameters: {'max_depth': 6, 'n_estimators': 175, 'min_samples_leaf': 2, 'min_samples_split': 17}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 14 finished.\n",
      "Best value after trial 14: 0.810\n",
      "Best params after trial 14: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:56,786] Trial 15 finished with value: 0.8083341966228117 and parameters: {'max_depth': 5, 'n_estimators': 173, 'min_samples_leaf': 4, 'min_samples_split': 16}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 15 finished.\n",
      "Best value after trial 15: 0.810\n",
      "Best params after trial 15: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[I 2023-08-28 15:15:57,793] Trial 16 finished with value: 0.8083341966228115 and parameters: {'max_depth': 6, 'n_estimators': 130, 'min_samples_leaf': 2, 'min_samples_split': 9}. Best is trial 1 with value: 0.8103801926862116.\n",
      "\n",
      "Trial 16 finished.\n",
      "Best value after trial 16: 0.810\n",
      "Best params after trial 16: {'max_depth': 7, 'n_estimators': 157, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
      "[W 2023-08-28 15:15:58,150] Trial 17 failed with parameters: {'max_depth': 6, 'n_estimators': 171, 'min_samples_leaf': 5, 'min_samples_split': 18} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/b2/7f14c80j6xs10nf7qg9bg8d80000gn/T/ipykernel_14600/3098720016.py\", line 21, in optuna_rf_function\n",
      "    cv_result = cross_validate(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 309, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/joblib/parallel.py\", line 1863, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/joblib/parallel.py\", line 1792, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 445, in fit\n",
      "    trees = [\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 446, in <listcomp>\n",
      "    self._make_estimator(append=False, random_state=random_state)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/ensemble/_base.py\", line 191, in _make_estimator\n",
      "    _set_random_states(estimator, random_state)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/ensemble/_base.py\", line 70, in _set_random_states\n",
      "    for key in sorted(estimator.get_params(deep=True)):\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/base.py\", line 193, in get_params\n",
      "    for key in self._get_param_names():\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/base.py\", line 158, in _get_param_names\n",
      "    init_signature = inspect.signature(init)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/inspect.py\", line 3113, in signature\n",
      "    return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/inspect.py\", line 2862, in from_callable\n",
      "    return _signature_from_callable(obj, sigcls=cls,\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/inspect.py\", line 2325, in _signature_from_callable\n",
      "    return _signature_from_function(sigcls, obj,\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/inspect.py\", line 2241, in _signature_from_function\n",
      "    return cls(parameters,\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/inspect.py\", line 2830, in __init__\n",
      "    params = OrderedDict((param.name, param) for param in parameters)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/inspect.py\", line 2830, in <genexpr>\n",
      "    params = OrderedDict((param.name, param) for param in parameters)\n",
      "  File \"/Users/alex/miniconda3/envs/biozone/lib/python3.9/inspect.py\", line 2548, in name\n",
      "    @property\n",
      "KeyboardInterrupt\n",
      "[W 2023-08-28 15:15:58,160] Trial 17 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Optimize the study using the sampler\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptuna_rf_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m, in \u001b[0;36moptuna_rf_function\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhyperparameters)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Evaluate the model using cross-validation and calculate the mean test score\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m cv_result \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:445\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# We draw from the random state to get the random state we\u001b[39;00m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# would have got if we hadn't used a warm_start.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_))\n\u001b[0;32m--> 445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m    456\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    457\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    458\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    474\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:446\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# We draw from the random state to get the random state we\u001b[39;00m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# would have got if we hadn't used a warm_start.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_))\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m    456\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    457\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    458\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    474\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/ensemble/_base.py:191\u001b[0m, in \u001b[0;36mBaseEnsemble._make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    188\u001b[0m estimator\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{p: \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator_params})\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     \u001b[43m_set_random_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m append:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mappend(estimator)\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/ensemble/_base.py:70\u001b[0m, in \u001b[0;36m_set_random_states\u001b[0;34m(estimator, random_state)\u001b[0m\n\u001b[1;32m     68\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(random_state)\n\u001b[1;32m     69\u001b[0m to_set \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__random_state\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     72\u001b[0m         to_set[key] \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax)\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/base.py:193\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mGet parameters for this estimator.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    Parameter names mapped to their values.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_param_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    194\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/site-packages/sklearn/base.py:158\u001b[0m, in \u001b[0;36mBaseEstimator._get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# introspect the constructor arguments to find the model parameters\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# to represent\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m init_signature \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Consider the constructor parameters excluding 'self'\u001b[39;00m\n\u001b[1;32m    160\u001b[0m parameters \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    161\u001b[0m     p\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m init_signature\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m p\u001b[38;5;241m.\u001b[39mVAR_KEYWORD\n\u001b[1;32m    164\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/inspect.py:3113\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   3112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/inspect.py:2862\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2863\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/inspect.py:2325\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mreplace(parameters\u001b[38;5;241m=\u001b[39mnew_params)\n\u001b[1;32m   2322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2323\u001b[0m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2324\u001b[0m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2330\u001b[0m                                    skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/inspect.py:2241\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2236\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(Parameter(name, annotation\u001b[38;5;241m=\u001b[39mannotation,\n\u001b[1;32m   2237\u001b[0m                                 kind\u001b[38;5;241m=\u001b[39m_VAR_KEYWORD))\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;66;03m# Is 'func' is a pure Python function - don't validate the\u001b[39;00m\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;66;03m# parameters list (for correct order and defaults), it should be OK.\u001b[39;00m\n\u001b[0;32m-> 2241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m           \u001b[49m\u001b[43mreturn_annotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreturn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_empty\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m           \u001b[49m\u001b[43m__validate_parameters__\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_duck_function\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/inspect.py:2830\u001b[0m, in \u001b[0;36mSignature.__init__\u001b[0;34m(self, parameters, return_annotation, __validate_parameters__)\u001b[0m\n\u001b[1;32m   2828\u001b[0m             params[name] \u001b[38;5;241m=\u001b[39m param\n\u001b[1;32m   2829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2830\u001b[0m         params \u001b[38;5;241m=\u001b[39m \u001b[43mOrderedDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mMappingProxyType(params)\n\u001b[1;32m   2833\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_annotation \u001b[38;5;241m=\u001b[39m return_annotation\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/inspect.py:2830\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2828\u001b[0m             params[name] \u001b[38;5;241m=\u001b[39m param\n\u001b[1;32m   2829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2830\u001b[0m         params \u001b[38;5;241m=\u001b[39m OrderedDict((\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m, param) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m parameters)\n\u001b[1;32m   2832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mMappingProxyType(params)\n\u001b[1;32m   2833\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_annotation \u001b[38;5;241m=\u001b[39m return_annotation\n",
      "File \u001b[0;32m~/miniconda3/envs/biozone/lib/python3.9/inspect.py:2548\u001b[0m, in \u001b[0;36mParameter.name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_default\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_annotation \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_annotation\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2548\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name\n\u001b[1;32m   2552\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def print_callback(study, trial):\n",
    "    # Print the trial number, the best value and parameters after each trial\n",
    "    print(f\"\\nTrial {trial.number} finished.\")\n",
    "    print(f\"Best value after trial {trial.number}: {study.best_value:.3f}\")\n",
    "    print(f\"Best params after trial {trial.number}: {study.best_params}\")\n",
    "\n",
    "\n",
    "# Define a function that specifies the model, the search space and trains the model\n",
    "# Optuna will try to optimize the hyperparameters to maximize the output of this function\n",
    "def optuna_rf_function(trial):\n",
    "    hyperparameters = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 8),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 32),\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**hyperparameters)\n",
    "\n",
    "    # Evaluate the model using cross-validation and calculate the mean test score\n",
    "    cv_result = cross_validate(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    return cv_result[\"test_score\"].mean()\n",
    "\n",
    "\n",
    "# Create an Optuna study object\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Optimize the study using the sampler\n",
    "study.optimize(\n",
    "    optuna_rf_function,\n",
    "    n_trials=100,\n",
    "    callbacks=[print_callback],\n",
    "    show_progress_bar=True,\n",
    "    gc_after_trial=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:12:51.482585Z",
     "start_time": "2023-08-28T18:12:51.193793Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1689199069230,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     },
     "user_tz": 240
    },
    "id": "c6RsdF9nJCkF",
    "outputId": "85f309ba-77a8-4720-991c-7d1dbf2ddf84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 4, 'n_estimators': 189, 'min_samples_leaf': 1, 'min_samples_split': 28}\n",
      "Best CV Accuracy: 81.75%\n",
      "Testing Accuracy: 80.79%\n"
     ]
    }
   ],
   "source": [
    "def print_accuracy(accuracy, dataset_name):\n",
    "    print(f\"{dataset_name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# Obtain the best parameters and their corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "# Display the best parameters and their corresponding accuracy\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print_accuracy(best_accuracy, \"Best CV\")\n",
    "\n",
    "# Train the best model on the training data\n",
    "best_model = RandomForestClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set and calculate the accuracy\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Display the test accuracy\n",
    "print_accuracy(test_accuracy, \"Testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfQzBH9VKUyU"
   },
   "source": [
    "**Your Turn**\n",
    "\n",
    "- How do the CV accuracies of the grid search and Optuna compare? They are very similar.\n",
    "- What differences do you notice in their testing accuracies? They are also very similar.\n",
    "- Which method completed faster, and why do you think this was the case? The Optuna method completed faster. This is because Optuna intelligently selects new configurations based on predictions from the surrogate model, thus converging to the optimal hyperparameters more rapidly and with fewer evaluations.\n",
    "\n",
    "Hyperparameter Tuning for Neural Networks\n",
    "\n",
    "One compelling use case for Bayesian Optimization is hyperparameter tuning for neural networks. Training these models can be time-consuming and their performance can be significantly affected by hyperparameters such as dropout rate, learning rate, weight decay, batch size, among others. Let's explore how we can optimize these parameters for a neural network.\n",
    "\n",
    "Our hyperparameters for this network will include:\n",
    "\n",
    "- The batch size utilized during training\n",
    "- The learning rate for the training process\n",
    "- The number of training epochs\n",
    "- The size of the hidden layer in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLPKZ119ZUHn"
   },
   "source": [
    "It's outside of the scope of this lab, but the code for our neural network is below. Thanks to our network class having fit and predict functions, we can actually reuse much of our code from the Random Forest example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:13:38.092210Z",
     "start_time": "2023-08-28T18:13:38.082496Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class TitanicMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple two-layer network for the Titanic dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, learning_rate, epochs):\n",
    "        super(TitanicMLP, self).__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Define the forward pass layers\n",
    "        self.forward_pass = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform the forward pass.\n",
    "        \"\"\"\n",
    "        return self.forward_pass(x)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "\n",
    "        # Create tensors\n",
    "        X_tensor = torch.Tensor(X).float()\n",
    "        Y_tensor = torch.Tensor(y).float()\n",
    "\n",
    "        # Create DataLoader\n",
    "        train_dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset, batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(self.epochs):\n",
    "            for batch_idx, (features, target) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()  # reset gradients\n",
    "                outputs = self.forward(features)  # forward pass\n",
    "                loss = self.criterion(\n",
    "                    torch.squeeze(outputs), torch.squeeze(target)\n",
    "                )  # calculate loss\n",
    "                loss.backward()  # backpropagation\n",
    "                self.optimizer.step()  # update weights\n",
    "\n",
    "            # Print progress\n",
    "            if (epoch + 1) % 10 == 0 and epoch != 0:\n",
    "                print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class of the input data X.\n",
    "        \"\"\"\n",
    "        self.eval()  # switch to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.Tensor(X)\n",
    "            y_pred = torch.sigmoid(\n",
    "                self.forward(X_tensor)\n",
    "            )  # apply sigmoid for binary output\n",
    "            y_pred = (\n",
    "                torch.round(y_pred).squeeze().numpy()\n",
    "            )  # round to nearest integer (0 or 1) and convert to numpy array\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\n",
    "**Your Turn**\n",
    "\n",
    "- Currently, the Hyperparameter search has some placeholder values passed in. Replace these fixed values with Optuna variables to search the space.\n",
    "- Examine the scores produced for the various parameter configurations tested by Optuna. Do they exhibit similar performance, or do they significantly influence the model's effectiveness?\n",
    "\n",
    "Answer: They exhibit similar performance - the Titanic dataset is not very complex, so the hyperparameters do not have a large impact on the model's effectiveness.\n",
    "\n",
    "Remember, the purpose of hyperparameter tuning is to optimize the model's performance, and sometimes even a minor change in parameters can lead to substantial improvement. So, it's crucial to pay close attention to the scores and make adjustments as necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:18:11.017007Z",
     "start_time": "2023-08-28T18:17:45.153954Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e0aef6ccaf6d43e1b5c400b2307a265e",
      "f21470133c574f5c9d0707c979038cbf",
      "ecf72f14216949e3b93f5f0f78f9baba",
      "6e6a13c6cb6640d2b874207cb29d487e",
      "7ea0dc58b97e422283f5822274fa68df",
      "41c5428891fb4b9e8e00545c027a4794",
      "171232bb06a841698fd3af2bef742cb7",
      "cf6ad7ae768647b6b317ca2266c9f784",
      "02f8ea4fe50c495cb38378ca1e16dc6b",
      "7c2094a8784c452dbf4bed4c449e1471",
      "6a85def097714d12943770ae703d7000"
     ]
    },
    "executionInfo": {
     "elapsed": 1286587,
     "status": "ok",
     "timestamp": 1689200358759,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     },
     "user_tz": 240
    },
    "id": "JNAl8udWXi8v",
    "outputId": "d139da5c-1812-460a-a91a-9d38284391d5"
   },
   "outputs": [],
   "source": [
    "def optuna_mlp_function(trial):\n",
    "    # Define the hyperparameters\n",
    "    hyperparameters = {\n",
    "        \"input_dim\": trial.suggest_categorical(\n",
    "            \"input_dim\", [X_train.shape[1]]\n",
    "        ),  # Fixed parameter, no need to include in the trial\n",
    "        \"hidden_dim\": trial.suggest_int(\"hidden_dim\", 8, 64),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 8, 64),  # Power of 2\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"epochs\": trial.suggest_categorical(\"epochs\", [10,20,30])\n",
    "    }\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = TitanicMLP(**hyperparameters)\n",
    "    scores = []\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_index, val_index in kfold.split(X_train, y_train):\n",
    "        X_train_fold = X_train[train_index]\n",
    "        y_train_fold = y_train.values[train_index]\n",
    "        X_val_fold = X_train[val_index]\n",
    "        y_val_fold = y_train.values[val_index]\n",
    "\n",
    "        # Fit the model and predict on the validation data\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "\n",
    "        # Append the accuracy score to the list of scores\n",
    "        scores.append(accuracy_score(y_val_fold, y_pred))\n",
    "\n",
    "    # Return the mean cross-validation accuracy\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Initialize the Optuna study and set the optimization direction\n",
    "mlp_study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Run the optimization\n",
    "mlp_study.optimize(\n",
    "    optuna_mlp_function,\n",
    "    n_trials=100,\n",
    "    callbacks=[print_callback],\n",
    "    show_progress_bar=True,\n",
    "    gc_after_trial=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-28T18:18:11.020392Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3265,
     "status": "ok",
     "timestamp": 1689200362022,
     "user": {
      "displayName": "Nakul Upadhya",
      "userId": "08924826005411940959"
     },
     "user_tz": 240
    },
    "id": "XU5CsRnAa4N9",
    "outputId": "34f5c470-8cb0-4152-93c1-a5b6277475a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'input_dim': 6, 'hidden_dim': 40, 'batch_size': 30, 'learning_rate': 0.06060997465428394, 'epochs': 30}\n",
      "Best CV Accuracy: 81.45%\n",
      "Epoch 10/30, Loss: 0.4147522449493408\n",
      "Epoch 20/30, Loss: 0.46157708764076233\n",
      "Epoch 30/30, Loss: 0.31265583634376526\n",
      "Testing Accuracy: 81.71%\n"
     ]
    }
   ],
   "source": [
    "best_params = mlp_study.best_params\n",
    "best_accuracy = mlp_study.best_value\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print_accuracy(best_accuracy, \"Best CV\")\n",
    "\n",
    "best_model = TitanicMLP(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print_accuracy(test_accuracy, \"Testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "in1P8TDhF8jV"
   },
   "source": [
    "**Your Turn**\n",
    "\n",
    "Besides the parameters we searched for above, can you think of other hyperparameters that could be tuned in a Neural Network?\n",
    "\n",
    "Hint: There are several aspects of a Neural Network's architecture and training process that can be adjusted. These could include the type of optimizer used, the activation functions applied, the initialization method for weights, and much more. Think about the various components that make up a Neural Network and how adjusting them might impact the model's performance.\n",
    "\n",
    "Answer: The type of optimizer used, the activation functions applied, the initialization method for weights, and much more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMcD6m6l8Ut8vEnqam8Fx4F",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02f8ea4fe50c495cb38378ca1e16dc6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0cd81b6de72048c8961aa7778b653a0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "171232bb06a841698fd3af2bef742cb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b58e8e784a045e08d6605205d63150a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d85108019624c6bb12a020175c24afe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "330269805d30447895208d5c4f79e728": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d85108019624c6bb12a020175c24afe",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0cd81b6de72048c8961aa7778b653a0b",
      "value": 100
     }
    },
    "3996aef1fc0f4b7ea9a5f6dbaffd4fba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e05c7217178646a1b362f13e93d7fc00",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6f35d1788d3b498ca7dccc8072a36daf",
      "value": "Best trial: 95. Best value: 0.817528: 100%"
     }
    },
    "41c5428891fb4b9e8e00545c027a4794": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a85def097714d12943770ae703d7000": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e6a13c6cb6640d2b874207cb29d487e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c2094a8784c452dbf4bed4c449e1471",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6a85def097714d12943770ae703d7000",
      "value": " 100/100 [21:26&lt;00:00, 15.40s/it]"
     }
    },
    "6f35d1788d3b498ca7dccc8072a36daf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76b654fd1e0a4da8b4a3bb949c286086": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c2094a8784c452dbf4bed4c449e1471": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ea0dc58b97e422283f5822274fa68df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a08383cb3b24b129429c401fa4e8df4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adee0055ed694b0a9f643a489d3fb08a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a08383cb3b24b129429c401fa4e8df4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1b58e8e784a045e08d6605205d63150a",
      "value": " 100/100 [02:04&lt;00:00,  1.24s/it]"
     }
    },
    "cf6ad7ae768647b6b317ca2266c9f784": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e05c7217178646a1b362f13e93d7fc00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0aef6ccaf6d43e1b5c400b2307a265e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f21470133c574f5c9d0707c979038cbf",
       "IPY_MODEL_ecf72f14216949e3b93f5f0f78f9baba",
       "IPY_MODEL_6e6a13c6cb6640d2b874207cb29d487e"
      ],
      "layout": "IPY_MODEL_7ea0dc58b97e422283f5822274fa68df"
     }
    },
    "ecf72f14216949e3b93f5f0f78f9baba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf6ad7ae768647b6b317ca2266c9f784",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02f8ea4fe50c495cb38378ca1e16dc6b",
      "value": 100
     }
    },
    "f21470133c574f5c9d0707c979038cbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41c5428891fb4b9e8e00545c027a4794",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_171232bb06a841698fd3af2bef742cb7",
      "value": "Best trial: 86. Best value: 0.79509: 100%"
     }
    },
    "f6d84beb6f8e477a9c0d45817accc8b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3996aef1fc0f4b7ea9a5f6dbaffd4fba",
       "IPY_MODEL_330269805d30447895208d5c4f79e728",
       "IPY_MODEL_adee0055ed694b0a9f643a489d3fb08a"
      ],
      "layout": "IPY_MODEL_76b654fd1e0a4da8b4a3bb949c286086"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
